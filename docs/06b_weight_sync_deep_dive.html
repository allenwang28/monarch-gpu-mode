<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/favicon.ico" />
    <!-- Preload is necessary because we show these images when we disconnect from the server,
    but at that point we cannot load these images from the server -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/gradient-yHQUC_QB.png" as="image" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/noise-60BoTA8O.png" as="image" />
    <!-- Preload the fonts -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Lora-VariableFont_wght-B2ootaw-.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/PTSans-Regular-CxL0S8W7.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/PTSans-Bold-D9fedIX3.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Regular-BTCkDNvf.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Medium-DU3aDxX5.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Bold-CLVRCuM9.ttf" as="font" crossorigin="anonymous" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="a marimo app" />
    <link rel="apple-touch-icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/apple-touch-icon.png" />
    <link rel="manifest" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/manifest.json" />

    <script data-marimo="true">
      function __resizeIframe(obj) {
        const scrollbarHeight = 20; // Max between windows, mac, and linux

        function setHeight() {
          // Guard against race condition where iframe isn't ready
          if (!obj.contentWindow?.document?.documentElement) {
            return;
          }
          const element = obj.contentWindow.document.documentElement;
          // If there is no vertical scrollbar, we don't need to resize the iframe
          if (element.scrollHeight === element.clientHeight) {
            return;
          }

          // Create a new height that includes the scrollbar height if it's visible
          const hasHorizontalScrollbar = element.scrollWidth > element.clientWidth;
          const newHeight = element.scrollHeight + (hasHorizontalScrollbar ? scrollbarHeight : 0);

          // Only update the height if it's different from the current height
          if (obj.style.height !== `${newHeight}px`) {
            obj.style.height = `${newHeight}px`;
          }
        }

        // Resize the iframe to the height of the content and bottom scrollbar height
        setHeight();

        // Resize the iframe when the content changes
        const resizeObserver = new ResizeObserver((_entries) => {
          setHeight();
        });
        // Only observe if iframe content is ready
        if (obj.contentWindow?.document?.body) {
          resizeObserver.observe(obj.contentWindow.document.body);
        }
      }
    </script>
    <marimo-filename hidden>06b_weight_sync_deep_dive.py</marimo-filename>
    <!-- TODO(Trevor): Legacy, required by VS Code plugin. Remove when plugin is updated (see marimo/server/_templates/template.py) -->
    <marimo-version data-version="{{ version }}" hidden></marimo-version>
    <marimo-user-config data-config="{{ user_config }}" hidden></marimo-user-config>
    <marimo-server-token data-token="{{ server_token }}" hidden></marimo-server-token>
    <!-- /TODO -->
    <title>06b weight sync deep dive</title>
    <script type="module" crossorigin crossorigin="anonymous" src="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/index-DGasP9Lh.js"></script>
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/preload-helper-DItdS47A.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/clsx-D8GwTfvk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cn-BKtXLv3a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chunk-LvLJmgfZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-BGmjiNul.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/compiler-runtime-DeeZ7FnK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/jsx-runtime-ZmTK25f3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/badge-Ce8wRjuQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/hotkeys-BHHWjLlp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useEventListener-DIUKKfEy.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/button-YC1gW_kJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-dom-C9fstfnp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Combination-CMPwuAmi.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/menu-items-CJhvWPOk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-uzvC4uAK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/createLucideIcon-CnW3RofX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/check-DdfN0k2d.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/select-V5IdpNiR.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/tooltip-CEc2ajau.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/use-toast-rmUWldD_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_Uint8Array-BGESiCQL.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseIsEqual-B9N9Mw_N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useEvent-DO6uJBas.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/invariant-CAG_dYON.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseFor-Duhs3RiJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/merge-BBX6ug-N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/zod-Cg4WLWh2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/utils-DXvhzCGS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/constants-B6Cb__3x.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Deferred-CrO5-0RA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/config-CIrPQIbt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/uuid-DercMavo.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/DeferredRequestRegistry-CO2AyNfd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/requests-BsVD4CdD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isSymbol-BGkTcW3U.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toString-DlRqgfqz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_hasUnicode-CWqKLxBC.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/assertNever-CBU83Y6o.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_arrayReduce-TT0iOGKY.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useLifecycle-D35CBukS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useNonce-_Aax6sXd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useTheme-DUdVAZI8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/once-Bul8mtFs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/capabilities-MM7JYRxj.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/createReducer-Dnna-AUO.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-DBwNzi3C.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-ChS0Dc_R.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-CtsanegT.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-BIKFl48f.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-B0VqT_4z.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-TiFCI16_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-Cayq-K1c.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-BYyu59D8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-Gqv0jSNr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/stex-CtmkcLz7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toDate-CgbKQM5E.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cjs-CH5Rj0g8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseProperty-NKyJO2oh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/now-6sUe0ZdD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/debounce-B3mjKxHe.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toInteger-CDcO32Gx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/database-zap-B9y7063w.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/main-U5Goe76G.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cells-BpZ7g6ok.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/spinner-DaIKav-i.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chevron-right-DwagBitu.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dropdown-menu-B-6unW-7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/kbd-C3JY7O_u.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/renderShortcut-DEwfrKeS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/multi-map-C8GlnP-4.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/alert-BrGyZf9c.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/alert-dialog-DwQffb13.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dialog-CxGKN4C_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-CdxIjAOP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/label-Be1daUcS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDebounce-D5NcotGm.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/textarea-DBO30D7K.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/numbers-iQunIAXf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/SSRProvider-CEHRCdjA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/context-JwD-oSsl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useNumberFormatter-c6GXymzg.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/usePress-Bup4EGrp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/input-pAun1m1X.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/links-DHZUhGz-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/popover-Gz-GJzym.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/switch-8sn_4qbh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/table-C8uQmBAN.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/mode-DX8pdI-l.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useAsyncData-C4XRy1BE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/errors-2SszdW9t.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/error-banner-DUzsIXtq.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-Bv2DBpIS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/memoize-BCOZVFBt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/get-6uJrSKbw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/capitalize-CmNnkG9y.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-CQ15EONK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/plus-BD5o34_i.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/refresh-cw-CQd-1kjx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/trash-2-CyqGun26.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/triangle-alert-B65rDESJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ai-model-dropdown-71lgLrLy.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/defaultLocale-D_rSvXvJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/precisionRound-BMPhtTJQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/defaultLocale-C92Rrpmf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/vega-loader.browser-CRZ52CKf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/tooltip-BGrCWNss.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ErrorBoundary-ChCiwl15.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useInstallPackage-Bdnnp5fe.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ImperativeModal-CUbWEBci.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cell-link-Bw5bzt4a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/datasource-B0OJBphG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/state-BfXVTTtD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/MarimoErrorOutput-5rudBbo3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-icon-BhONVREY.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/html-to-image-DjukyIj4.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/focus-D51fcwZX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/LazyAnyLanguageCodeMirror-yzHjsVJt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chunk-5FQGJX7Z-CVUXBqX6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/katex-Dc8yG8NU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/markdown-renderer-DhMlG2dP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/command-DhzFN2CJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/download-BhCZMKuQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useRunCells-24p6hn99.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/purify.es-DNVQZNFu.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/RenderHTML-CQZqVk1Z.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useIframeCapabilities-DuIDx9mD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/formats-W1SWxSE3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/en-US-pRRbZZHE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isValid-DcYggVWP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dates-Dhn1r-h6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/maps-t9yNKYA8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/extends-B2LJnKU3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/emotion-is-prop-valid.esm-DD4AwVTU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDateFormatter-CS4kbWl2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/range-D2UKkEg-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/table-DZR6ewbN.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/JsonOutput-CknFTI_u.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/file-Cs1JbsV6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/play-BPIh-ZEU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chat-components-CGlO4yUw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isEmpty-CgX_-6Mt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chat-display-B4mGvJ0X.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDeleteCell-5uYlTcQZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/icons-BhEXrzsb.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/process-output-CagdHMzs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/blob-CuXvdYPX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/objectWithoutPropertiesLoose-DaPAPabU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/esm-DpMp6qko.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/add-cell-with-ai-pVFp5LZG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chart-no-axes-column-W42b2ZIs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/square-function-CqXXKtIq.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/spec-D1kBp3jX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/column-preview-CxMrs0B_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toggle-jWKnIArU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/globals-DKH14XH0.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/share-CbPtIlnM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseSet-5Rdwpmr3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-resizable-panels.browser.esm-Ctj_10o2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/utilities.esm-CIPARd6-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/floating-outline-DcxjrFFt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useAddCell-BmeZUK02.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/eye-off-BhExYOph.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/readonly-python-code-DyP9LVLc.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/file-video-camera-DW3v07j2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/types-DuQOSW7G.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/refresh-ccw-DLEiQDS3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/form-DUA_Rz_a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/field-BEg1eC0P.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useBoolean-B1Xeh6vA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDeepCompareMemoize-ZPd9PxYl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/types-CS34eOZi.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/prop-types-BiQYf0aU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/es-D8BOePqo.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/hasIn-CycJImp8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseFlatten-CUZNxU8H.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/flatten-D-7VEN0q.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/pick-B_6Qi5aM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/code-xml-XLwHyDBr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/download-B9SUL40m.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/house-DhFkiXz7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/settings-DOXWMfVd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/square-C8Tw_XXG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/bundle.esm-2AjO7UK5.js">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cells-jmgGt1lS.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/markdown-renderer-DdDKmWlR.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/JsonOutput-B7vuddcd.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/index-CikhHYAB.css">
  
<script data-marimo="true">
    window.__MARIMO_STATIC__ = {};
    window.__MARIMO_STATIC__.files = {};
</script>
</head>
  <body>
    <div id="root"></div>
    <!-- This is a portal for the data editor to render in -->
    <div id="portal" data-testid="glide-portal" style="position: fixed; left: 0; top: 0; z-index: 9999"></div>
    <script data-marimo="true">
      window.__MARIMO_MOUNT_CONFIG__ = {
            "filename": "06b_weight_sync_deep_dive.py",
            "mode": "read",
            "version": "0.19.7",
            "serverToken": "static",
            "config": {"ai": {"custom_providers": {}, "models": {"custom_models": [], "displayed_models": []}}, "completion": {"activate_on_typing": true, "copilot": false, "signature_hint_on_typing": false}, "diagnostics": {"sql_linter": true}, "display": {"cell_output": "below", "code_editor_font_size": 14, "dataframes": "rich", "default_table_max_columns": 50, "default_table_page_size": 10, "default_width": "medium", "reference_highlighting": true, "theme": "light"}, "formatting": {"line_length": 79}, "keymap": {"overrides": {}, "preset": "default"}, "language_servers": {"pylsp": {"enable_flake8": false, "enable_mypy": true, "enable_pydocstyle": false, "enable_pyflakes": false, "enable_pylint": false, "enable_ruff": true, "enabled": false}}, "mcp": {"mcpServers": {}, "presets": []}, "package_management": {"manager": "uv"}, "runtime": {"auto_instantiate": false, "auto_reload": "off", "default_csv_encoding": "utf-8", "default_sql_output": "auto", "on_cell_change": "autorun", "output_max_bytes": 8000000, "reactive_tests": true, "std_stream_max_bytes": 1000000, "watcher_on_save": "lazy"}, "save": {"autosave": "after_delay", "autosave_delay": 1000, "format_on_save": false}, "server": {"browser": "default", "follow_symlink": false}, "snippets": {"custom_paths": [], "include_default_snippets": true}},
            "configOverrides": {},
            "appConfig": {"sql_output": "auto", "width": "medium"},
            "view": {"showAppCode": true},
            "notebook": {"cells": [{"code": "import marimo as mo", "code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hbol", "name": "_"}, {"code": "# Shared imports for the notebook\nimport time\nimport torch\nfrom monarch.actor import Actor, endpoint, this_host, current_rank\nfrom monarch.rdma import RDMABuffer, RDMAAction, is_rdma_available", "code_hash": "c7ac4d3804661f4817e054cbe05bc1c5", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "MJUe", "name": "_"}, {"code": "mo.md(r\"\"\"\n# Weight Sync Deep Dive\n\nThis notebook goes deeper into the implementation details of RDMA-based weight\nsynchronization. If you haven't read **Notebook 06: RDMA \u0026 Weight Sync**, start there\nfor the conceptual foundation.\n\n**What's covered here:**\n\n1. **ibverbs Internals** - Queue Pairs, Memory Registration, how Monarch wraps it\n2. **Memory Registration Costs** - Benchmarking naive vs optimized approaches\n3. **Circular Weight Buffer Implementation** - Full working code\n4. **DTensor Re-sharding** - Computing transfer plans, the full benchmark\n\nThis is the \"how it works under the hood\" companion to the main notebook.\n\"\"\")", "code_hash": "664e3f5c8a3d002fc807c615be26a8ca", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "vblA", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 1. ibverbs Internals\n\nRDMA (Remote Direct Memory Access) lets one machine read/write another machine's memory\ndirectly, bypassing the kernel and CPU on both sides.\n\n### The ibverbs Stack\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Application (PyTorch, Monarch, etc.)                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  libibverbs  (userspace RDMA API)                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Provider driver (mlx5, efa, rxe, etc.)                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Hardware (InfiniBand NIC, RoCE NIC, etc.)              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nWe focus on **InfiniBand** and **RoCE** (RDMA over Converged Ethernet).\n\n### Key RDMA Operations\n\n| Operation | Description |\n|-----------|-------------|\n| `RDMA_WRITE` | Write to remote memory (one-sided) |\n| `RDMA_READ` | Read from remote memory (one-sided) |\n| `SEND/RECV` | Two-sided messaging (like TCP) |\n\nThe magic is in `RDMA_WRITE` and `RDMA_READ` - they're **one-sided**:\n- Remote CPU is not involved\n- Remote application doesn't need to call anything\n- NIC handles everything in hardware\n\n### Memory Registration\n\nBefore RDMA, memory must be **registered** with the NIC:\n\n```python\n# Conceptually (actual ibverbs API is in C)\nmr = rdma_register_memory(buffer, size)\n# Returns:\n#   - lkey: local access key (for local operations)\n#   - rkey: remote access key (share with remote peer)\n#   - addr: physical/virtual address\n```\n\nThe `(addr, rkey)` pair is a **remote-accessible pointer**. Share it with a peer,\nand they can read/write your memory directly.\n\n### Queue Pair Setup\n\nBefore any RDMA operations, you need to establish a **Queue Pair (QP)** between\nsender and receiver. This is a one-time connection setup:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Sender    \u2502                           \u2502  Receiver   \u2502\n\u2502             \u2502                           \u2502             \u2502\n\u2502  Create QP  \u2502 \u2500\u2500\u2500 exchange QP info \u2500\u2500\u2500\u25ba \u2502  Create QP  \u2502\n\u2502  (qp_num,   \u2502 \u25c4\u2500\u2500 (qp_num, lid, gid) \u2500\u2500 \u2502             \u2502\n\u2502   lid, gid) \u2502                           \u2502             \u2502\n\u2502             \u2502                           \u2502             \u2502\n\u2502  Move QP to \u2502                           \u2502  Move QP to \u2502\n\u2502  RTR \u2192 RTS  \u2502                           \u2502  RTR \u2192 RTS  \u2502\n\u2502             \u2502                           \u2502             \u2502\n\u2502  Now ready  \u2502 \u2550\u2550\u2550 RDMA operations \u2550\u2550\u2550\u2550\u25ba \u2502  Now ready  \u2502\n\u2502  for RDMA!  \u2502                           \u2502  for RDMA!  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThis is where **Monarch actors** shine. Because you can spawn arbitrary actors,\nyou can create **RDMA Manager actors** that:\n- Initialize QPs on their respective hosts\n- Exchange QP info via actor messages\n- Manage the connection lifecycle\n\n```python\n# Monarch pattern: RDMA managers as actors\nclass RDMAManager(Actor):\n    def __init__(self):\n        self.qp = create_queue_pair()\n        self.qp_info = get_qp_info(self.qp)  # (qp_num, lid, gid)\n\n    @endpoint\n    def get_qp_info(self) -\u003E QpInfo:\n        return self.qp_info\n\n    @endpoint\n    def connect(self, remote_qp_info: QpInfo):\n        # Transition QP: INIT \u2192 RTR \u2192 RTS\n        connect_qp(self.qp, remote_qp_info)\n\n# Setup: exchange QP info via actor messages, then RDMA is ready\ntrainer_info = trainer_rdma.get_qp_info.call_one().get()\ngenerator_rdma.connect.call_one(trainer_info).get()\n```\n\nThe actor abstraction makes RDMA connection management natural and composable.\n\"\"\")", "code_hash": "c5e05e0a6938be7012a942dbf2812250", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "bkHC", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Monarch Using Monarch: RdmaController\n\nHere's the cool part: **Monarch uses itself** to manage RDMA infrastructure. Looking at\nthe actual Python code in `monarch/_src/rdma/rdma.py`:\n\n```python\n# From Monarch's RDMA implementation\nfrom monarch._src.actor.proc_mesh import get_or_spawn_controller\n\nclass RdmaController(Actor):\n    '''Singleton controller that coordinates RDMA initialization.'''\n\n    def __init__(self):\n        # Track which proc meshes have RDMA initialized\n        self._manager_futures: dict[ProcMesh, Future[RdmaManager]] = {}\n\n    @endpoint\n    async def init_rdma_on_mesh(self, proc_mesh: ProcMesh) -\u003E None:\n        '''Lazily initialize RDMA on a proc mesh.'''\n        if proc_mesh not in self._manager_futures:\n            self._manager_futures[proc_mesh] = Future(\n                coro=RdmaManager.create(proc_mesh)\n            )\n        await self._manager_futures[proc_mesh]\n\n# Cached initialization - only runs once per process\n@functools.cache\ndef _ensure_init_rdma_manager():\n    async def task():\n        controller = await get_or_spawn_controller(\"rdma_controller\", RdmaController)\n        await controller.init_rdma_on_mesh.call_one(current_proc_mesh())\n    return spawn_task(task())\n```\n\nThis is **Monarch building Monarch** - the RDMA subsystem uses the same patterns:\n\n- `get_or_spawn_controller(\"rdma_controller\", RdmaController)` ensures one global controller\n- The controller lazily initializes RDMA managers per proc mesh\n- `@functools.cache` ensures we only bootstrap once per process\n- Under the hood, the actual RDMA operations are in Rust (`RdmaManagerActor`)\n\nIt's actors all the way down.\n\"\"\")", "code_hash": "f30f8fb1555d6d664d81e5f2fdf0454e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "lEQa", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 2. Memory Registration Costs\n\nRDMA memory registration is **expensive**:\n- Pins physical pages (prevents swapping)\n- Creates IOMMU/DMA mappings in the NIC\n- Can take milliseconds for large buffers\n\nBut here's the good news: **Monarch caches all memory region registrations.** Once a buffer\nis registered, subsequent uses hit the cache, making it essentially free in steady state.\n\nLet's benchmark 3 approaches to see this in action.\n\"\"\")", "code_hash": "34246b290724fee80eb311e3506e940a", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "PKri", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Approach 1: Naive\n\nCreate new RDMABuffer on each transfer - registration happens on first use:\n\"\"\")", "code_hash": "1cc5ea5d89d69c99ff5170b212a4ea7e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Xref", "name": "_"}, {"code": "class NaiveSender(Actor):\n    \"\"\"Creates new RDMABuffer handles every transfer. Expensive!\"\"\"\n\n    def __init__(self, layer_sizes: list):\n        self.layer_sizes = layer_sizes\n        self.layers = [torch.zeros(size, dtype=torch.float32) for size in layer_sizes]\n        for i, layer in enumerate(self.layers):\n            layer.fill_(float(i + 1))\n\n    @endpoint\n    def get_fresh_handles(self) -\u003E list:\n        handles = []\n        for size, layer in zip(self.layer_sizes, self.layers):\n            byte_view = layer.view(torch.uint8).flatten()\n            handles.append((size, RDMABuffer(byte_view)))\n        return handles\n\n\nclass NaiveReceiver(Actor):\n    \"\"\"Receives from naive sender - pays MR cost every step.\"\"\"\n\n    def __init__(self, layer_sizes: list):\n        self.layer_sizes = layer_sizes\n        self.layers = [torch.zeros(size, dtype=torch.float32) for size in layer_sizes]\n        self.rank = current_rank().rank\n\n    @endpoint\n    def receive_step(self, sender: NaiveSender) -\u003E dict:\n        start = time.perf_counter()\n        handles = sender.get_fresh_handles.call_one().get()\n        for i, (size, handle) in enumerate(handles):\n            byte_view = self.layers[i].view(torch.uint8).flatten()\n            handle.read_into(byte_view).get()\n        elapsed_ms = (time.perf_counter() - start) * 1000\n        return {\"elapsed_ms\": elapsed_ms}\n\nprint(\"NaiveSender: Re-registers all parameters on every call\")", "code_hash": "cb0763f4294eadb91b3e3d6ecb7660ee", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "SFPL", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Approach 2: Contiguous Buffer\n\nAllocate one buffer, register at init time:\n\"\"\")", "code_hash": "71fa8fb63791c29cc9852d10b6d0c808", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "BYtC", "name": "_"}, {"code": "class ContiguousSender(Actor):\n    \"\"\"One buffer, one MR, registered at startup.\"\"\"\n\n    def __init__(self, layer_sizes: list):\n        self.layer_sizes = layer_sizes\n        total_size = sum(layer_sizes)\n\n        # One contiguous buffer\n        self.buffer = torch.zeros(total_size, dtype=torch.float32)\n        offset = 0\n        for i, size in enumerate(layer_sizes):\n            self.buffer[offset : offset + size].fill_(float(i + 1))\n            offset += size\n\n        # Register ONCE at startup\n        byte_view = self.buffer.view(torch.uint8).flatten()\n        self.handle = RDMABuffer(byte_view)\n\n    @endpoint\n    def get_handle(self) -\u003E tuple:\n        return (len(self.buffer), self.handle)  # Same handle every time!\n\n\nclass ContiguousReceiver(Actor):\n    \"\"\"Receives from contiguous sender - fast after first step.\"\"\"\n\n    def __init__(self, total_size: int):\n        self.buffer = torch.zeros(total_size, dtype=torch.float32)\n        self.rank = current_rank().rank\n\n    @endpoint\n    def receive_step(self, sender: ContiguousSender) -\u003E dict:\n        start = time.perf_counter()\n        size, handle = sender.get_handle.call_one().get()\n        byte_view = self.buffer.view(torch.uint8).flatten()\n        handle.read_into(byte_view).get()\n        elapsed_ms = (time.perf_counter() - start) * 1000\n        return {\"elapsed_ms\": elapsed_ms}\n\nprint(\"ContiguousSender: Registers once, reuses same handle\")", "code_hash": "b20940a01eb850b248043c377b34e75c", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "RGSE", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Approach 3: Scattered + RDMAAction\n\nRegister each buffer at init, build transfer plan once via handshake:\n\n**What is RDMAAction?**\n\nThink of `RDMAAction` as a **transfer plan**. You describe all the reads/writes you want\nto do, then `submit()` executes the whole plan at once:\n\n```python\n# Build the plan once\naction = RDMAAction()\naction.read_into(handle1, local_buffer1)\naction.read_into(handle2, local_buffer2)\naction.read_into(handle3, local_buffer3)\n\n# Execute whenever you want - just one call\naction.submit().get()\n```\n\nThis is useful when you have many scattered buffers (like model parameters) and want\nto batch them into a single logical operation.\n\"\"\")", "code_hash": "520c3b2b3e217c6bfff43b76fe3e0157", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Kclp", "name": "_"}, {"code": "class ScatteredSender(Actor):\n    \"\"\"Multiple buffers, each registered once at startup.\"\"\"\n\n    def __init__(self, layer_sizes: list):\n        self.layer_sizes = layer_sizes\n        self.layers = []\n        self.handles = []\n\n        for i, size in enumerate(layer_sizes):\n            layer = torch.zeros(size, dtype=torch.float32)\n            layer.fill_(float(i + 1))\n            self.layers.append(layer)\n            # Register ONCE at startup\n            byte_view = layer.view(torch.uint8).flatten()\n            self.handles.append(RDMABuffer(byte_view))\n\n    @endpoint\n    def get_handles(self) -\u003E list:\n        return [(size, handle) for size, handle in zip(self.layer_sizes, self.handles)]\n\nclass ScatteredReceiver(Actor):\n    \"\"\"Receives from scattered sender with RDMAAction batching.\"\"\"\n\n    def __init__(self, layer_sizes: list):\n        self.layer_sizes = layer_sizes\n        self.layers = [torch.zeros(size, dtype=torch.float32) for size in layer_sizes]\n        self.rank = current_rank().rank\n        self.action = None  # Built on handshake\n\n    @endpoint\n    def handshake(self, sender: ScatteredSender):\n        \"\"\"Call once to build the RDMAAction transfer plan.\"\"\"\n        handles = sender.get_handles.call_one().get()\n        self.action = RDMAAction()\n        for i, (size, handle) in enumerate(handles):\n            byte_view = self.layers[i].view(torch.uint8).flatten()\n            self.action.read_into(handle, byte_view)\n        return \"Transfer plan ready\"\n\n    @endpoint\n    def receive_step(self) -\u003E dict:\n        \"\"\"Execute the cached transfer plan.\"\"\"\n        start = time.perf_counter()\n        self.action.submit().get()\n        elapsed_ms = (time.perf_counter() - start) * 1000\n        return {\"elapsed_ms\": elapsed_ms}\n\nprint(\"ScatteredSender: Registers each layer once\")\nprint(\"ScatteredReceiver: handshake() builds plan, receive_step() executes it\")", "code_hash": "cf2558bd29e83f53df64e3e26f3b7b6d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "emfo", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Running the Benchmark\n\"\"\")", "code_hash": "b0fba7d210a61fd3620db9561c51d39e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hstk", "name": "_"}, {"code": "def run_benchmark():\n    \"\"\"Compare the three approaches over multiple steps.\"\"\"\n    layer_sizes = [1000, 5000, 2000]  # 8000 floats total\n    total_size = sum(layer_sizes)\n    num_steps = 5\n\n    host = this_host()\n    sender_procs = host.spawn_procs(per_host={\"procs\": 1})\n    receiver_procs = host.spawn_procs(per_host={\"procs\": 1})\n\n    print(\"=== RDMA Registration Benchmark ===\")\n    print(f\"Transferring {total_size} floats ({total_size * 4 / 1024:.1f} KB) x {num_steps} steps\\n\")\n\n    results = {}\n\n    # Naive approach\n    naive_sender = sender_procs.spawn(\"naive_s\", NaiveSender, layer_sizes)\n    naive_receiver = receiver_procs.spawn(\"naive_r\", NaiveReceiver, layer_sizes)\n    times = []\n    for step in range(num_steps):\n        r = naive_receiver.receive_step.call_one(naive_sender).get()\n        times.append(r[\"elapsed_ms\"])\n    results[\"Naive\"] = times\n    print(f\"Naive (re-register each step):\")\n    for i, t in enumerate(times):\n        print(f\"  Step {i+1}: {t:.2f}ms\")\n    print(f\"  Average: {sum(times)/len(times):.2f}ms\\n\")\n\n    # Contiguous approach\n    cont_sender = sender_procs.spawn(\"cont_s\", ContiguousSender, layer_sizes)\n    cont_receiver = receiver_procs.spawn(\"cont_r\", ContiguousReceiver, total_size)\n    times = []\n    for step in range(num_steps):\n        r = cont_receiver.receive_step.call_one(cont_sender).get()\n        times.append(r[\"elapsed_ms\"])\n    results[\"Contiguous\"] = times\n    print(f\"Contiguous (register once):\")\n    for i, t in enumerate(times):\n        print(f\"  Step {i+1}: {t:.2f}ms\")\n    print(f\"  Average: {sum(times)/len(times):.2f}ms\\n\")\n\n    # Scattered + RDMAAction approach\n    scat_sender = sender_procs.spawn(\"scat_s\", ScatteredSender, layer_sizes)\n    scat_receiver = receiver_procs.spawn(\"scat_r\", ScatteredReceiver, layer_sizes)\n    scat_receiver.handshake.call_one(scat_sender).get()  # Build transfer plan once\n    times = []\n    for step in range(num_steps):\n        r = scat_receiver.receive_step.call_one().get()  # Just execute cached plan\n        times.append(r[\"elapsed_ms\"])\n    results[\"Scattered\"] = times\n    print(f\"Scattered + RDMAAction (register once, batch):\")\n    for i, t in enumerate(times):\n        print(f\"  Step {i+1}: {t:.2f}ms\")\n    print(f\"  Average: {sum(times)/len(times):.2f}ms\\n\")\n\n    print(\"=== What's Happening ===\")\n    print(\"Naive step 1: Cold MR registration (~2000ms)\")\n    print(\"Naive steps 2+: Cache hit, MR already registered (~10ms)\")\n    print(\"Contiguous/Scattered: Registration happened at spawn time, not during benchmark\")\n\n    return results\n\nbenchmark_results = run_benchmark()", "code_hash": "a31f2c0f5cf8b1d37bad845ac21bdb09", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "nWHF", "name": "_"}, {"code": "mo.md(r\"\"\"\n**What the benchmark shows:**\n\n- **Naive**: First call is ~2000ms (cold registration), subsequent calls ~10ms (cache hit)\n- **Contiguous/Scattered**: All calls are fast (~4-9ms) because registration happened\n  at spawn time, before the timing loop started\n\n*Note: RDMAAction (~9ms) is slower than Contiguous (~4ms) due to Python overhead.\nMoving the batching logic to Rust is a planned optimization.*\n\"\"\")", "code_hash": "cb64b2d65765fb608f01d2e9c51384c0", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "iLit", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 3. Circular Weight Buffer Implementation\n\nHere's a full working implementation of a circular buffer for versioned weight storage.\nIn production, this would be used inside a Monarch actor and slots would be registered\nwith RDMABuffer at init time.\n\"\"\")", "code_hash": "2e3307a399cc6ca9fcf31c5b36d1cd55", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZHCJ", "name": "_"}, {"code": "from threading import Lock as _Lock\nfrom typing import Tuple as _Tuple, Optional as _Opt\n\nclass CircularWeightBuffer:\n    \"\"\"Circular buffer for versioned weight storage.\n\n    In production, this would be used inside a Monarch actor and slots\n    would be registered with RDMABuffer at init time.\n    \"\"\"\n\n    def __init__(self, template_tensor: torch.Tensor, n_slots: int = 3):\n        self.n_slots = n_slots\n        self.slots = [\n            torch.empty_like(template_tensor).pin_memory()\n            if template_tensor.device.type == \"cpu\"\n            else torch.empty_like(template_tensor, device=\"cpu\").pin_memory()\n            for _ in range(n_slots)\n        ]\n        self.latest_version = 0\n        self._lock = _Lock()\n\n        # In production (inside a Monarch actor):\n        # self.rdma_handles = [RDMABuffer(slot.view(torch.uint8).flatten()) for slot in self.slots]\n        # This pre-registers all slots with RDMA at init time (amortizes MR cost)\n\n    def publish(self, weights: torch.Tensor) -\u003E int:\n        \"\"\"Trainer publishes new weights. Returns version number.\"\"\"\n        with self._lock:\n            slot_idx = self.latest_version % self.n_slots\n            self.slots[slot_idx].copy_(weights)\n            self.latest_version += 1\n            return self.latest_version - 1\n\n    def get_latest(self) -\u003E _Tuple[torch.Tensor, int]:\n        \"\"\"Generator gets latest weights. Non-blocking.\"\"\"\n        with self._lock:\n            if self.latest_version == 0:\n                raise RuntimeError(\"No weights published yet\")\n            slot_idx = (self.latest_version - 1) % self.n_slots\n            version = self.latest_version - 1\n            return self.slots[slot_idx].clone(), version\n\n    def get_version(self, version: int) -\u003E _Opt[torch.Tensor]:\n        \"\"\"Get specific version if still available.\"\"\"\n        with self._lock:\n            oldest_available = max(0, self.latest_version - self.n_slots)\n            if version \u003C oldest_available or version \u003E= self.latest_version:\n                return None\n            slot_idx = version % self.n_slots\n            return self.slots[slot_idx].clone()\n\n# Demo\n_template = torch.randn(100, 100)\nweight_buffer = CircularWeightBuffer(_template, n_slots=3)\n\n# Trainer publishes versions\nfor _v in range(5):\n    _new_weights = torch.randn(100, 100) * (_v + 1)\n    published_v = weight_buffer.publish(_new_weights)\n    print(f\"Published version {published_v}\")\n\n# Generator grabs latest\nlatest_weights, latest_version = weight_buffer.get_latest()\nprint(f\"\\nGenerator got version {latest_version}, weights mean: {latest_weights.mean():.2f}\")\n\n# Try to get old version (might be evicted)\nold_weights = weight_buffer.get_version(1)\nprint(f\"Version 1 available: {old_weights is not None}\")\n\nprint(\"\\nIn production: RDMABuffer handles would be pre-registered at init time\")\nprint(\"Generators would call get_latest_handle() to get RDMA handle + version\")", "code_hash": "d6d5d71e57550b8cb9c32b20239ef5bc", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ROlb", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 4. DTensor Re-sharding Implementation\n\nWhen trainer and generator have different tensor layouts (sharding), we need to compute\nwhich chunks of data need to move from which source to which destination.\n\n### Computing Shard Metadata\n\"\"\")", "code_hash": "abb852ba33401102e12403ffe9ca3011", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "qnkX", "name": "_"}, {"code": "from dataclasses import dataclass\nfrom typing import List, Tuple\n\n@dataclass\nclass ShardMetadata:\n    \"\"\"Metadata describing a tensor shard.\"\"\"\n    rank: int\n    global_shape: Tuple[int, ...]\n    offset: Tuple[int, ...]  # Start position in global tensor\n    local_shape: Tuple[int, ...]  # Shape of this shard\n\ndef compute_shard_metadata(\n    global_shape: Tuple[int, int],\n    num_ranks: int,\n    shard_dim: int,\n) -\u003E List[ShardMetadata]:\n    \"\"\"Compute shard metadata for a given sharding.\"\"\"\n    shards = []\n    dim_size = global_shape[shard_dim]\n    shard_size = dim_size // num_ranks\n\n    for rank in range(num_ranks):\n        offset = [0, 0]\n        local_shape = list(global_shape)\n\n        offset[shard_dim] = rank * shard_size\n        local_shape[shard_dim] = shard_size\n\n        shards.append(ShardMetadata(\n            rank=rank,\n            global_shape=global_shape,\n            offset=tuple(offset),\n            local_shape=tuple(local_shape),\n        ))\n\n    return shards\n\n# Demo: Trainer has row-sharding, Generator has column-sharding\n_global_shape = (1024, 1024)\n\ntrainer_shards = compute_shard_metadata(_global_shape, num_ranks=4, shard_dim=0)\ngenerator_shards = compute_shard_metadata(_global_shape, num_ranks=2, shard_dim=1)\n\nprint(\"Trainer shards (row-wise, 4 GPUs):\")\nfor s in trainer_shards:\n    print(f\"  Rank {s.rank}: offset={s.offset}, shape={s.local_shape}\")\n\nprint(\"\\nGenerator shards (column-wise, 2 GPUs):\")\nfor s in generator_shards:\n    print(f\"  Rank {s.rank}: offset={s.offset}, shape={s.local_shape}\")", "code_hash": "01a93cde7e5ea82b6a4aa8a7a8c4acf8", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "TqIu", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Computing Transfer Plans\n\nGiven source and destination sharding, compute the minimal set of transfers needed:\n\"\"\")", "code_hash": "5fb456160925752ab4805f509b1f7b7d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Vxnm", "name": "_"}, {"code": "@dataclass\nclass TransferChunk:\n    \"\"\"A chunk to transfer from sender to receiver.\"\"\"\n    sender_rank: int\n    receiver_rank: int\n    sender_offset: Tuple[int, int]  # Where to read from sender\n    receiver_offset: Tuple[int, int]  # Where to write in receiver\n    shape: Tuple[int, int]  # Shape of the chunk\n\ndef compute_overlap(\n    sender: ShardMetadata,\n    receiver: ShardMetadata,\n) -\u003E TransferChunk | None:\n    \"\"\"Compute overlap between sender and receiver shards.\"\"\"\n    # Find intersection in global coordinates\n    s_start = sender.offset\n    s_end = (s_start[0] + sender.local_shape[0], s_start[1] + sender.local_shape[1])\n\n    r_start = receiver.offset\n    r_end = (r_start[0] + receiver.local_shape[0], r_start[1] + receiver.local_shape[1])\n\n    # Compute intersection\n    inter_start = (max(s_start[0], r_start[0]), max(s_start[1], r_start[1]))\n    inter_end = (min(s_end[0], r_end[0]), min(s_end[1], r_end[1]))\n\n    # Check if there's actual overlap\n    if inter_start[0] \u003E= inter_end[0] or inter_start[1] \u003E= inter_end[1]:\n        return None\n\n    shape = (inter_end[0] - inter_start[0], inter_end[1] - inter_start[1])\n\n    # Convert to local coordinates\n    sender_local = (inter_start[0] - s_start[0], inter_start[1] - s_start[1])\n    receiver_local = (inter_start[0] - r_start[0], inter_start[1] - r_start[1])\n\n    return TransferChunk(\n        sender_rank=sender.rank,\n        receiver_rank=receiver.rank,\n        sender_offset=sender_local,\n        receiver_offset=receiver_local,\n        shape=shape,\n    )\n\ndef compute_transfer_plan(\n    sender_shards: List[ShardMetadata],\n    receiver_shards: List[ShardMetadata],\n) -\u003E List[TransferChunk]:\n    \"\"\"Compute all transfers needed for re-sharding.\"\"\"\n    transfers = []\n    for sender in sender_shards:\n        for receiver in receiver_shards:\n            chunk = compute_overlap(sender, receiver)\n            if chunk is not None:\n                transfers.append(chunk)\n    return transfers\n\n# Compute transfer plan\ntransfer_plan = compute_transfer_plan(trainer_shards, generator_shards)\n\nprint(f\"Transfer plan: {len(transfer_plan)} chunks needed\\n\")\nfor chunk in transfer_plan:\n    print(f\"Sender {chunk.sender_rank} \u2192 Receiver {chunk.receiver_rank}\")\n    print(f\"  Read from sender offset {chunk.sender_offset}, shape {chunk.shape}\")\n    print(f\"  Write to receiver offset {chunk.receiver_offset}\")\n    print()", "code_hash": "dd9ef142fcda82825b003d755d4b8bc5", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "DnEU", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Full DTensor Benchmark\n\nThis benchmark uses actual DTensor with different placements to show the savings\nfrom routed transfers vs gather-then-slice.\n\"\"\")", "code_hash": "d1e0bc27cdab552e42c7c74a06dac372", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ulZA", "name": "_"}, {"code": "import os\nfrom torch.distributed._tensor import DTensor, Shard, Replicate, init_device_mesh\n\n# Configuration\nNUM_TRAINER_RANKS = 4\nNUM_GENERATOR_RANKS = 2\n\n# Layer configs: (global_shape, trainer_placement, generator_placement)\nLAYER_CONFIGS = [\n    {\"shape\": (1024, 1024), \"trainer_place\": Shard(0), \"gen_place\": Shard(0)},\n    {\"shape\": (512, 2048), \"trainer_place\": Shard(1), \"gen_place\": Shard(1)},\n    {\"shape\": (256, 256), \"trainer_place\": Replicate(), \"gen_place\": Replicate()},\n]\n\ndef placement_to_shard_dim(placement) -\u003E int | None:\n    \"\"\"Extract shard dimension from DTensor placement.\"\"\"\n    if isinstance(placement, Shard):\n        return placement.dim\n    return None\n\ndef compute_layer_transfer_plan(layer_cfg, trainer_ranks, gen_ranks, gen_rank):\n    \"\"\"Use DTensor placement metadata to compute transfer plan for one layer.\"\"\"\n    trainer_dim = placement_to_shard_dim(layer_cfg[\"trainer_place\"])\n    gen_dim = placement_to_shard_dim(layer_cfg[\"gen_place\"])\n\n    if trainer_dim is None:\n        return [(0, None)]\n\n    if gen_dim is None:\n        return [(t, None) for t in range(trainer_ranks)]\n\n    trainer_shards = compute_shard_metadata(layer_cfg[\"shape\"], trainer_ranks, trainer_dim)\n    gen_shards = compute_shard_metadata(layer_cfg[\"shape\"], gen_ranks, gen_dim)\n    my_shard = gen_shards[gen_rank]\n\n    overlapping = []\n    for t_shard in trainer_shards:\n        t_start = t_shard.offset[trainer_dim]\n        t_end = t_start + t_shard.local_shape[trainer_dim]\n        g_start = my_shard.offset[gen_dim] if gen_dim == trainer_dim else 0\n        g_end = (my_shard.offset[gen_dim] + my_shard.local_shape[gen_dim]\n                 if gen_dim == trainer_dim else layer_cfg[\"shape\"][trainer_dim])\n\n        if t_end \u003E g_start and t_start \u003C g_end:\n            overlapping.append((t_shard.rank, t_shard))\n\n    return overlapping\n\nclass DTensorTrainer(Actor):\n    \"\"\"Trainer with DTensor shards.\"\"\"\n\n    def __init__(self):\n        self.rank = current_rank().rank\n        self.dtensors = []\n        self.handles = []\n        self.device_mesh = None\n\n    @endpoint\n    def setup_distributed(self):\n        world_size = int(os.environ.get(\"WORLD_SIZE\", \"1\"))\n\n        if not torch.distributed.is_initialized():\n            torch.distributed.init_process_group(backend=\"gloo\")\n\n        self.device_mesh = init_device_mesh(\"cpu\", (world_size,))\n\n        for i, cfg in enumerate(LAYER_CONFIGS):\n            placement = cfg[\"trainer_place\"]\n            shard_dim = placement_to_shard_dim(placement)\n\n            if shard_dim is not None:\n                local_shape = list(cfg[\"shape\"])\n                local_shape[shard_dim] = cfg[\"shape\"][shard_dim] // world_size\n                local_shape = tuple(local_shape)\n            else:\n                local_shape = cfg[\"shape\"]\n\n            local_tensor = torch.zeros(local_shape, dtype=torch.float32)\n            local_tensor.fill_(float(i * 10 + self.rank))\n\n            dt = DTensor.from_local(local_tensor, self.device_mesh, [placement], run_check=False)\n            self.dtensors.append(dt)\n            self.handles.append(RDMABuffer(local_tensor.view(torch.uint8).flatten()))\n\n        shapes = [tuple(dt.to_local().shape) for dt in self.dtensors]\n        placements = [str(cfg[\"trainer_place\"]) for cfg in LAYER_CONFIGS]\n        print(f\"Trainer {self.rank}: shapes={shapes}, placements={placements}\")\n        return shapes\n\n    @endpoint\n    def get_layer_handle(self, layer_idx: int):\n        return (tuple(self.dtensors[layer_idx].to_local().shape), self.handles[layer_idx])\n\n    @endpoint\n    def destroy(self):\n        if torch.distributed.is_initialized():\n            torch.distributed.destroy_process_group()\n\nclass DTensorGenerator(Actor):\n    \"\"\"Generator that uses DTensor placement metadata for smart resharding.\"\"\"\n\n    def __init__(self):\n        self.rank = current_rank().rank\n        self.action = None\n        self.recv_buffers = []\n        self.device_mesh = None\n\n    @endpoint\n    def setup_distributed(self):\n        world_size = int(os.environ.get(\"WORLD_SIZE\", \"1\"))\n        if not torch.distributed.is_initialized():\n            torch.distributed.init_process_group(backend=\"gloo\")\n        self.device_mesh = init_device_mesh(\"cpu\", (world_size,))\n        print(f\"Generator {self.rank}: distributed initialized\")\n        return world_size\n\n    @endpoint\n    def handshake_routed(self, trainers):\n        \"\"\"Routed approach: use DTensor placements to compute minimal transfers.\"\"\"\n        self.action = RDMAAction()\n        self.recv_buffers = []\n        total_transfers = 0\n\n        for layer_idx, cfg in enumerate(LAYER_CONFIGS):\n            overlapping = compute_layer_transfer_plan(\n                cfg, NUM_TRAINER_RANKS, NUM_GENERATOR_RANKS, self.rank\n            )\n\n            for t_rank, _ in overlapping:\n                shape, handle = trainers[t_rank].get_layer_handle.call_one(layer_idx).get()\n                buf = torch.zeros(shape, dtype=torch.float32)\n                self.recv_buffers.append(buf)\n                self.action.read_into(handle, buf.view(torch.uint8).flatten())\n                total_transfers += 1\n\n        return f\"Routed: {total_transfers} transfers (placement-aware)\"\n\n    @endpoint\n    def receive_routed(self) -\u003E dict:\n        start = time.perf_counter()\n        self.action.submit().get()\n        elapsed_ms = (time.perf_counter() - start) * 1000\n        return {\"elapsed_ms\": elapsed_ms}\n\n    @endpoint\n    def destroy(self):\n        if torch.distributed.is_initialized():\n            torch.distributed.destroy_process_group()\n\nprint(\"DTensor actors defined\")", "code_hash": "b744064169f2a7c386d2c28187413213", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ecfG", "name": "_"}, {"code": "from monarch.spmd import setup_torch_elastic_env\n\n_trainer_procs = this_host().spawn_procs(per_host={\"procs\": NUM_TRAINER_RANKS})\nsetup_torch_elastic_env(_trainer_procs)\n_trainers = _trainer_procs.spawn(\"trainers\", DTensorTrainer)\n\n_gen_procs = this_host().spawn_procs(per_host={\"procs\": NUM_GENERATOR_RANKS})\nsetup_torch_elastic_env(_gen_procs)\n_generators = _gen_procs.spawn(\"generators\", DTensorGenerator)\n\nprint(\"\\n=== DTensor Reshard Benchmark ===\")\nprint(f\"Trainer mesh: {NUM_TRAINER_RANKS} ranks, Generator mesh: {NUM_GENERATOR_RANKS} ranks\")\nprint(\"Layer configs:\")\nfor i, cfg in enumerate(LAYER_CONFIGS):\n    print(f\"  Layer {i}: {cfg['shape']}, trainer={cfg['trainer_place']}, gen={cfg['gen_place']}\")\n\nprint(\"\\nSetting up distributed...\")\n_trainer_shapes = _trainers.setup_distributed.call().get()\n_gen_world = _generators.setup_distributed.call().get()\nprint(f\"  Trainer shapes: {[s for _, s in _trainer_shapes]}\")\nprint(f\"  Generator world sizes: {[w for _, w in _gen_world]}\")\n\n_trainer_list = [_trainers.slice(procs=i) for i in range(NUM_TRAINER_RANKS)]\n\nprint(\"\\nBuilding transfer plans (using placement metadata)...\")\n_results = _generators.handshake_routed.call(_trainer_list).get()\nfor _i, _r in enumerate(_results):\n    print(f\"  Generator {_i}: {_r}\")\n\nprint(\"\\nRunning transfers...\")\n_times = []\nfor _step in range(3):\n    _step_start = time.perf_counter()\n    _results = _generators.receive_routed.call().get()\n    _step_ms = (time.perf_counter() - _step_start) * 1000\n    _times.append(_step_ms)\n    print(f\"  Step {_step + 1}: {_step_ms:.1f}ms\")\n\n_avg = sum(_times) / len(_times)\nprint(f\"  Average: {_avg:.1f}ms\")\n\n_trainers.destroy.call().get()\n_generators.destroy.call().get()\nprint(\"\\nDistributed cleanup complete\")", "code_hash": "45e6b97ddf26e9962dc8db24bcf00d22", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Pvdt", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Summary\n\nThis deep dive covered:\n\n1. **ibverbs internals** - QP setup, MR registration, how Monarch wraps it all\n2. **Memory registration costs** - Why naive approaches are slow, how caching helps\n3. **Circular weight buffers** - Full implementation with versioning\n4. **DTensor re-sharding** - Computing transfer plans from placement metadata\n\nThese are the building blocks that make Monarch's weight sync fast and flexible.\nThe main notebook (06) covers when and why to use these patterns.\n\"\"\")", "code_hash": "0f02466a370fb7841c0b74194aaa32b4", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZBYS", "name": "_"}], "metadata": {"marimo_version": "0.19.7"}, "version": "1"},
            "session": {"cells": [{"code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "console": [], "id": "Hbol", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "c7ac4d3804661f4817e054cbe05bc1c5", "console": [], "id": "MJUe", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "664e3f5c8a3d002fc807c615be26a8ca", "console": [], "id": "vblA", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch1 id=\"weight-sync-deep-dive\"\u003EWeight Sync Deep Dive\u003C/h1\u003E\n\u003Cspan class=\"paragraph\"\u003EThis notebook goes deeper into the implementation details of RDMA-based weight\nsynchronization. If you haven't read \u003Cstrong\u003ENotebook 06: RDMA \u0026amp; Weight Sync\u003C/strong\u003E, start there\nfor the conceptual foundation.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWhat's covered here:\u003C/strong\u003E\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003E\u003Cstrong\u003Eibverbs Internals\u003C/strong\u003E - Queue Pairs, Memory Registration, how Monarch wraps it\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EMemory Registration Costs\u003C/strong\u003E - Benchmarking naive vs optimized approaches\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ECircular Weight Buffer Implementation\u003C/strong\u003E - Full working code\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EDTensor Re-sharding\u003C/strong\u003E - Computing transfer plans, the full benchmark\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is the \"how it works under the hood\" companion to the main notebook.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "c5e05e0a6938be7012a942dbf2812250", "console": [], "id": "bkHC", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"1-ibverbs-internals\"\u003E1. ibverbs Internals\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003ERDMA (Remote Direct Memory Access) lets one machine read/write another machine's memory\ndirectly, bypassing the kernel and CPU on both sides.\u003C/span\u003E\n\u003Ch3 id=\"the-ibverbs-stack\"\u003EThe ibverbs Stack\u003C/h3\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Application (PyTorch, Monarch, etc.)                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  libibverbs  (userspace RDMA API)                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Provider driver (mlx5, efa, rxe, etc.)                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Hardware (InfiniBand NIC, RoCE NIC, etc.)              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EWe focus on \u003Cstrong\u003EInfiniBand\u003C/strong\u003E and \u003Cstrong\u003ERoCE\u003C/strong\u003E (RDMA over Converged Ethernet).\u003C/span\u003E\n\u003Ch3 id=\"key-rdma-operations\"\u003EKey RDMA Operations\u003C/h3\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EOperation\u003C/th\u003E\n\u003Cth\u003EDescription\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003ERDMA_WRITE\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003EWrite to remote memory (one-sided)\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003ERDMA_READ\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003ERead from remote memory (one-sided)\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003ESEND/RECV\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003ETwo-sided messaging (like TCP)\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003EThe magic is in \u003Ccode\u003ERDMA_WRITE\u003C/code\u003E and \u003Ccode\u003ERDMA_READ\u003C/code\u003E - they're \u003Cstrong\u003Eone-sided\u003C/strong\u003E:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ERemote CPU is not involved\u003C/li\u003E\n\u003Cli\u003ERemote application doesn't need to call anything\u003C/li\u003E\n\u003Cli\u003ENIC handles everything in hardware\u003C/li\u003E\n\u003C/ul\u003E\n\u003Ch3 id=\"memory-registration\"\u003EMemory Registration\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EBefore RDMA, memory must be \u003Cstrong\u003Eregistered\u003C/strong\u003E with the NIC:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E# Conceptually (actual ibverbs API is in C)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Emr\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Erdma_register_memory\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Esize\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"c1\"\u003E# Returns:\u003C/span\u003E\n\u003Cspan class=\"c1\"\u003E#   - lkey: local access key (for local operations)\u003C/span\u003E\n\u003Cspan class=\"c1\"\u003E#   - rkey: remote access key (share with remote peer)\u003C/span\u003E\n\u003Cspan class=\"c1\"\u003E#   - addr: physical/virtual address\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe \u003Ccode\u003E(addr, rkey)\u003C/code\u003E pair is a \u003Cstrong\u003Eremote-accessible pointer\u003C/strong\u003E. Share it with a peer,\nand they can read/write your memory directly.\u003C/span\u003E\n\u003Ch3 id=\"queue-pair-setup\"\u003EQueue Pair Setup\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EBefore any RDMA operations, you need to establish a \u003Cstrong\u003EQueue Pair (QP)\u003C/strong\u003E between\nsender and receiver. This is a one-time connection setup:\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Sender    \u2502                           \u2502  Receiver   \u2502\n\u2502             \u2502                           \u2502             \u2502\n\u2502  Create QP  \u2502 \u2500\u2500\u2500 exchange QP info \u2500\u2500\u2500\u25ba \u2502  Create QP  \u2502\n\u2502  (qp_num,   \u2502 \u25c4\u2500\u2500 (qp_num, lid, gid) \u2500\u2500 \u2502             \u2502\n\u2502   lid, gid) \u2502                           \u2502             \u2502\n\u2502             \u2502                           \u2502             \u2502\n\u2502  Move QP to \u2502                           \u2502  Move QP to \u2502\n\u2502  RTR \u2192 RTS  \u2502                           \u2502  RTR \u2192 RTS  \u2502\n\u2502             \u2502                           \u2502             \u2502\n\u2502  Now ready  \u2502 \u2550\u2550\u2550 RDMA operations \u2550\u2550\u2550\u2550\u25ba \u2502  Now ready  \u2502\n\u2502  for RDMA!  \u2502                           \u2502  for RDMA!  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is where \u003Cstrong\u003EMonarch actors\u003C/strong\u003E shine. Because you can spawn arbitrary actors,\nyou can create \u003Cstrong\u003ERDMA Manager actors\u003C/strong\u003E that:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EInitialize QPs on their respective hosts\u003C/li\u003E\n\u003Cli\u003EExchange QP info via actor messages\u003C/li\u003E\n\u003Cli\u003EManage the connection lifecycle\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E# Monarch pattern: RDMA managers as actors\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Eclass\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nc\"\u003ERDMAManager\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003EActor\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"fm\"\u003E__init__\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eqp\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Ecreate_queue_pair\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eqp_info\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Eget_qp_info\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eqp\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E  \u003Cspan class=\"c1\"\u003E# (qp_num, lid, gid)\u003C/span\u003E\n\n    \u003Cspan class=\"nd\"\u003E@endpoint\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Eget_qp_info\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E \u003Cspan class=\"o\"\u003E-\u0026gt;\u003C/span\u003E \u003Cspan class=\"n\"\u003EQpInfo\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Ereturn\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eqp_info\u003C/span\u003E\n\n    \u003Cspan class=\"nd\"\u003E@endpoint\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Econnect\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eremote_qp_info\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E \u003Cspan class=\"n\"\u003EQpInfo\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n        \u003Cspan class=\"c1\"\u003E# Transition QP: INIT \u2192 RTR \u2192 RTS\u003C/span\u003E\n        \u003Cspan class=\"n\"\u003Econnect_qp\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eqp\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eremote_qp_info\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Setup: exchange QP info via actor messages, then RDMA is ready\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Etrainer_info\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Etrainer_rdma\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget_qp_info\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall_one\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Egenerator_rdma\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Econnect\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall_one\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etrainer_info\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe actor abstraction makes RDMA connection management natural and composable.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "f30f8fb1555d6d664d81e5f2fdf0454e", "console": [], "id": "lEQa", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"monarch-using-monarch-rdmacontroller\"\u003EMonarch Using Monarch: RdmaController\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EHere's the cool part: \u003Cstrong\u003EMonarch uses itself\u003C/strong\u003E to manage RDMA infrastructure. Looking at\nthe actual Python code in \u003Ccode\u003Emonarch/_src/rdma/rdma.py\u003C/code\u003E:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E# From Monarch\u0026#39;s RDMA implementation\u003C/span\u003E\n\u003Cspan class=\"kn\"\u003Efrom\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Emonarch._src.actor.proc_mesh\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"kn\"\u003Eimport\u003C/span\u003E \u003Cspan class=\"n\"\u003Eget_or_spawn_controller\u003C/span\u003E\n\n\u003Cspan class=\"k\"\u003Eclass\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nc\"\u003ERdmaController\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003EActor\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"sd\"\u003E\u0026#39;\u0026#39;\u0026#39;Singleton controller that coordinates RDMA initialization.\u0026#39;\u0026#39;\u0026#39;\u003C/span\u003E\n\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"fm\"\u003E__init__\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n        \u003Cspan class=\"c1\"\u003E# Track which proc meshes have RDMA initialized\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003E_manager_futures\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E \u003Cspan class=\"nb\"\u003Edict\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003EProcMesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003EFuture\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003ERdmaManager\u003C/span\u003E\u003Cspan class=\"p\"\u003E]]\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"p\"\u003E{}\u003C/span\u003E\n\n    \u003Cspan class=\"nd\"\u003E@endpoint\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Easync\u003C/span\u003E \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Einit_rdma_on_mesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eproc_mesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E \u003Cspan class=\"n\"\u003EProcMesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E \u003Cspan class=\"o\"\u003E-\u0026gt;\u003C/span\u003E \u003Cspan class=\"kc\"\u003ENone\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"sd\"\u003E\u0026#39;\u0026#39;\u0026#39;Lazily initialize RDMA on a proc mesh.\u0026#39;\u0026#39;\u0026#39;\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Eif\u003C/span\u003E \u003Cspan class=\"n\"\u003Eproc_mesh\u003C/span\u003E \u003Cspan class=\"ow\"\u003Enot\u003C/span\u003E \u003Cspan class=\"ow\"\u003Ein\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003E_manager_futures\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n            \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003E_manager_futures\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eproc_mesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003EFuture\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\n                \u003Cspan class=\"n\"\u003Ecoro\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"n\"\u003ERdmaManager\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecreate\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eproc_mesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n            \u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003E_manager_futures\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eproc_mesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Cached initialization - only runs once per process\u003C/span\u003E\n\u003Cspan class=\"nd\"\u003E@functools\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecache\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003E_ensure_init_rdma_manager\u003C/span\u003E\u003Cspan class=\"p\"\u003E():\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Easync\u003C/span\u003E \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Etask\u003C/span\u003E\u003Cspan class=\"p\"\u003E():\u003C/span\u003E\n        \u003Cspan class=\"n\"\u003Econtroller\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Eget_or_spawn_controller\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;rdma_controller\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003ERdmaController\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Econtroller\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Einit_rdma_on_mesh\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall_one\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecurrent_proc_mesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Ereturn\u003C/span\u003E \u003Cspan class=\"n\"\u003Espawn_task\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etask\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is \u003Cstrong\u003EMonarch building Monarch\u003C/strong\u003E - the RDMA subsystem uses the same patterns:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Ccode\u003Eget_or_spawn_controller(\"rdma_controller\", RdmaController)\u003C/code\u003E ensures one global controller\u003C/li\u003E\n\u003Cli\u003EThe controller lazily initializes RDMA managers per proc mesh\u003C/li\u003E\n\u003Cli\u003E\u003Ccode\u003E@functools.cache\u003C/code\u003E ensures we only bootstrap once per process\u003C/li\u003E\n\u003Cli\u003EUnder the hood, the actual RDMA operations are in Rust (\u003Ccode\u003ERdmaManagerActor\u003C/code\u003E)\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EIt's actors all the way down.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "34246b290724fee80eb311e3506e940a", "console": [], "id": "PKri", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"2-memory-registration-costs\"\u003E2. Memory Registration Costs\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003ERDMA memory registration is \u003Cstrong\u003Eexpensive\u003C/strong\u003E:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EPins physical pages (prevents swapping)\u003C/li\u003E\n\u003Cli\u003ECreates IOMMU/DMA mappings in the NIC\u003C/li\u003E\n\u003Cli\u003ECan take milliseconds for large buffers\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EBut here's the good news: \u003Cstrong\u003EMonarch caches all memory region registrations.\u003C/strong\u003E Once a buffer\nis registered, subsequent uses hit the cache, making it essentially free in steady state.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003ELet's benchmark 3 approaches to see this in action.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "1cc5ea5d89d69c99ff5170b212a4ea7e", "console": [], "id": "Xref", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"approach-1-naive\"\u003EApproach 1: Naive\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ECreate new RDMABuffer on each transfer - registration happens on first use:\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "cb0763f4294eadb91b3e3d6ecb7660ee", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "NaiveSender: Re-registers all parameters on every call\n", "type": "stream"}], "id": "SFPL", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "71fa8fb63791c29cc9852d10b6d0c808", "console": [], "id": "BYtC", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"approach-2-contiguous-buffer\"\u003EApproach 2: Contiguous Buffer\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EAllocate one buffer, register at init time:\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "b20940a01eb850b248043c377b34e75c", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "ContiguousSender: Registers once, reuses same handle\n", "type": "stream"}], "id": "RGSE", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "520c3b2b3e217c6bfff43b76fe3e0157", "console": [], "id": "Kclp", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"approach-3-scattered-rdmaaction\"\u003EApproach 3: Scattered + RDMAAction\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ERegister each buffer at init, build transfer plan once via handshake:\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWhat is RDMAAction?\u003C/strong\u003E\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThink of \u003Ccode\u003ERDMAAction\u003C/code\u003E as a \u003Cstrong\u003Etransfer plan\u003C/strong\u003E. You describe all the reads/writes you want\nto do, then \u003Ccode\u003Esubmit()\u003C/code\u003E executes the whole plan at once:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E# Build the plan once\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eaction\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMAAction\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eaction\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eread_into\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle1\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Elocal_buffer1\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eaction\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eread_into\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle2\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Elocal_buffer2\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eaction\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eread_into\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle3\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Elocal_buffer3\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Execute whenever you want - just one call\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eaction\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Esubmit\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is useful when you have many scattered buffers (like model parameters) and want\nto batch them into a single logical operation.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "cf2558bd29e83f53df64e3e26f3b7b6d", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "ScatteredSender: Registers each layer once\nScatteredReceiver: handshake() builds plan, receive_step() executes it\n", "type": "stream"}], "id": "emfo", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "b0fba7d210a61fd3620db9561c51d39e", "console": [], "id": "Hstk", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"running-the-benchmark\"\u003ERunning the Benchmark\u003C/h3\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "a31f2c0f5cf8b1d37bad845ac21bdb09", "console": [{"mimetype": "text/plain", "name": "stderr", "text": "Monarch internal logs are being written to /tmp/allencwang/monarch_log.log; execution id allencwang_Feb-06_15:07_838\n", "type": "stream"}, {"mimetype": "text/plain", "name": "stdout", "text": "=== RDMA Registration Benchmark ===\nTransferring 8000 floats (31.2 KB) x 5 steps\n\nNaive (re-register each step):\n  Step 1: 3531.57ms\n  Step 2: 12.76ms\n  Step 3: 12.19ms\n  Step 4: 11.58ms\n  Step 5: 12.76ms\n  Average: 716.17ms\n\nContiguous (register once):\n  Step 1: 4.30ms\n  Step 2: 4.40ms\n  Step 3: 3.93ms\n  Step 4: 4.45ms\n  Step 5: 3.46ms\n  Average: 4.11ms\n\nScattered + RDMAAction (register once, batch):\n  Step 1: 9.09ms\n  Step 2: 8.66ms\n  Step 3: 8.28ms\n  Step 4: 7.30ms\n  Step 5: 9.26ms\n  Average: 8.52ms\n\n=== What's Happening ===\nNaive step 1: Cold MR registration (~2000ms)\nNaive steps 2+: Cache hit, MR already registered (~10ms)\nContiguous/Scattered: Registration happened at spawn time, not during benchmark\n", "type": "stream"}], "id": "nWHF", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "cb64b2d65765fb608f01d2e9c51384c0", "console": [], "id": "iLit", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWhat the benchmark shows:\u003C/strong\u003E\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003ENaive\u003C/strong\u003E: First call is ~2000ms (cold registration), subsequent calls ~10ms (cache hit)\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EContiguous/Scattered\u003C/strong\u003E: All calls are fast (~4-9ms) because registration happened\n  at spawn time, before the timing loop started\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cem\u003ENote: RDMAAction (~9ms) is slower than Contiguous (~4ms) due to Python overhead.\nMoving the batching logic to Rust is a planned optimization.\u003C/em\u003E\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "2e3307a399cc6ca9fcf31c5b36d1cd55", "console": [], "id": "ZHCJ", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"3-circular-weight-buffer-implementation\"\u003E3. Circular Weight Buffer Implementation\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EHere's a full working implementation of a circular buffer for versioned weight storage.\nIn production, this would be used inside a Monarch actor and slots would be registered\nwith RDMABuffer at init time.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "d6d5d71e57550b8cb9c32b20239ef5bc", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "Published version 0\nPublished version 1\nPublished version 2\nPublished version 3\nPublished version 4\n\nGenerator got version 4, weights mean: 0.09\nVersion 1 available: False\n\nIn production: RDMABuffer handles would be pre-registered at init time\nGenerators would call get_latest_handle() to get RDMA handle + version\n", "type": "stream"}], "id": "ROlb", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "abb852ba33401102e12403ffe9ca3011", "console": [], "id": "qnkX", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"4-dtensor-re-sharding-implementation\"\u003E4. DTensor Re-sharding Implementation\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EWhen trainer and generator have different tensor layouts (sharding), we need to compute\nwhich chunks of data need to move from which source to which destination.\u003C/span\u003E\n\u003Ch3 id=\"computing-shard-metadata\"\u003EComputing Shard Metadata\u003C/h3\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "01a93cde7e5ea82b6a4aa8a7a8c4acf8", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "Trainer shards (row-wise, 4 GPUs):\n  Rank 0: offset=(0, 0), shape=(256, 1024)\n  Rank 1: offset=(256, 0), shape=(256, 1024)\n  Rank 2: offset=(512, 0), shape=(256, 1024)\n  Rank 3: offset=(768, 0), shape=(256, 1024)\n\nGenerator shards (column-wise, 2 GPUs):\n  Rank 0: offset=(0, 0), shape=(1024, 512)\n  Rank 1: offset=(0, 512), shape=(1024, 512)\n", "type": "stream"}], "id": "TqIu", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "5fb456160925752ab4805f509b1f7b7d", "console": [], "id": "Vxnm", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"computing-transfer-plans\"\u003EComputing Transfer Plans\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EGiven source and destination sharding, compute the minimal set of transfers needed:\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "dd9ef142fcda82825b003d755d4b8bc5", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "Transfer plan: 8 chunks needed\n\nSender 0 \u2192 Receiver 0\n  Read from sender offset (0, 0), shape (256, 512)\n  Write to receiver offset (0, 0)\n\nSender 0 \u2192 Receiver 1\n  Read from sender offset (0, 512), shape (256, 512)\n  Write to receiver offset (0, 0)\n\nSender 1 \u2192 Receiver 0\n  Read from sender offset (0, 0), shape (256, 512)\n  Write to receiver offset (256, 0)\n\nSender 1 \u2192 Receiver 1\n  Read from sender offset (0, 512), shape (256, 512)\n  Write to receiver offset (256, 0)\n\nSender 2 \u2192 Receiver 0\n  Read from sender offset (0, 0), shape (256, 512)\n  Write to receiver offset (512, 0)\n\nSender 2 \u2192 Receiver 1\n  Read from sender offset (0, 512), shape (256, 512)\n  Write to receiver offset (512, 0)\n\nSender 3 \u2192 Receiver 0\n  Read from sender offset (0, 0), shape (256, 512)\n  Write to receiver offset (768, 0)\n\nSender 3 \u2192 Receiver 1\n  Read from sender offset (0, 512), shape (256, 512)\n  Write to receiver offset (768, 0)\n\n", "type": "stream"}], "id": "DnEU", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "d1e0bc27cdab552e42c7c74a06dac372", "console": [], "id": "ulZA", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"full-dtensor-benchmark\"\u003EFull DTensor Benchmark\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EThis benchmark uses actual DTensor with different placements to show the savings\nfrom routed transfers vs gather-then-slice.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "b744064169f2a7c386d2c28187413213", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "DTensor actors defined\n", "type": "stream"}], "id": "ecfG", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "45e6b97ddf26e9962dc8db24bcf00d22", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "\n=== DTensor Reshard Benchmark ===\nTrainer mesh: 4 ranks, Generator mesh: 2 ranks\nLayer configs:\n  Layer 0: (1024, 1024), trainer=S(0), gen=S(0)\n  Layer 1: (512, 2048), trainer=S(1), gen=S(1)\n  Layer 2: (256, 256), trainer=R, gen=R\n\nSetting up distributed...\n[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\nTrainer 0: shapes=[(256, 1024), (512, 512), (256, 256)], placements=['S(0)', 'S(1)', 'R']\nTrainer 3: shapes=[(256, 1024), (512, 512), (256, 256)], placements=['S(0)', 'S(1)', 'R']\nTrainer 2: shapes=[(256, 1024), (512, 512), (256, 256)], placements=['S(0)', 'S(1)', 'R']\nTrainer 1: shapes=[(256, 1024), (512, 512), (256, 256)], placements=['S(0)', 'S(1)', 'R']\n[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\nGenerator 0: distributed initialized\nGenerator 1: distributed initialized\n  Trainer shapes: [[(256, 1024), (512, 512), (256, 256)], [(256, 1024), (512, 512), (256, 256)], [(256, 1024), (512, 512), (256, 256)], [(256, 1024), (512, 512), (256, 256)]]\n  Generator world sizes: [2, 2]\n\nBuilding transfer plans (using placement metadata)...\n  Generator 0: ({'procs': 0/2}, 'Routed: 5 transfers (placement-aware)')\n  Generator 1: ({'procs': 1/2}, 'Routed: 5 transfers (placement-aware)')\n\nRunning transfers...\n  Step 1: 1331.1ms\n  Step 2: 12.4ms\n  Step 3: 10.6ms\n  Average: 451.4ms\n\nDistributed cleanup complete\n", "type": "stream"}], "id": "Pvdt", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "0f02466a370fb7841c0b74194aaa32b4", "console": [], "id": "ZBYS", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"summary\"\u003ESummary\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EThis deep dive covered:\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003E\u003Cstrong\u003Eibverbs internals\u003C/strong\u003E - QP setup, MR registration, how Monarch wraps it all\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EMemory registration costs\u003C/strong\u003E - Why naive approaches are slow, how caching helps\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ECircular weight buffers\u003C/strong\u003E - Full implementation with versioning\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EDTensor re-sharding\u003C/strong\u003E - Computing transfer plans from placement metadata\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003EThese are the building blocks that make Monarch's weight sync fast and flexible.\nThe main notebook (06) covers when and why to use these patterns.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}], "metadata": {"marimo_version": "0.19.7"}, "version": "1"},
            "runtimeConfig": null,
        };
    </script>
  
<marimo-code hidden="">
    import%20marimo%0A%0A__generated_with%20%3D%20%220.19.7%22%0Aapp%20%3D%20marimo.App(width%3D%22medium%22)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20marimo%20as%20mo%0A%20%20%20%20return%20(mo%2C)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20%23%20Shared%20imports%20for%20the%20notebook%0A%20%20%20%20import%20time%0A%20%20%20%20import%20torch%0A%20%20%20%20from%20monarch.actor%20import%20Actor%2C%20endpoint%2C%20this_host%2C%20current_rank%0A%20%20%20%20from%20monarch.rdma%20import%20RDMABuffer%2C%20RDMAAction%2C%20is_rdma_available%0A%20%20%20%20return%20(%0A%20%20%20%20%20%20%20%20Actor%2C%0A%20%20%20%20%20%20%20%20RDMAAction%2C%0A%20%20%20%20%20%20%20%20RDMABuffer%2C%0A%20%20%20%20%20%20%20%20current_rank%2C%0A%20%20%20%20%20%20%20%20endpoint%2C%0A%20%20%20%20%20%20%20%20this_host%2C%0A%20%20%20%20%20%20%20%20time%2C%0A%20%20%20%20%20%20%20%20torch%2C%0A%20%20%20%20)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%20Weight%20Sync%20Deep%20Dive%0A%0A%20%20%20%20This%20notebook%20goes%20deeper%20into%20the%20implementation%20details%20of%20RDMA-based%20weight%0A%20%20%20%20synchronization.%20If%20you%20haven't%20read%20**Notebook%2006%3A%20RDMA%20%26%20Weight%20Sync**%2C%20start%20there%0A%20%20%20%20for%20the%20conceptual%20foundation.%0A%0A%20%20%20%20**What's%20covered%20here%3A**%0A%0A%20%20%20%201.%20**ibverbs%20Internals**%20-%20Queue%20Pairs%2C%20Memory%20Registration%2C%20how%20Monarch%20wraps%20it%0A%20%20%20%202.%20**Memory%20Registration%20Costs**%20-%20Benchmarking%20naive%20vs%20optimized%20approaches%0A%20%20%20%203.%20**Circular%20Weight%20Buffer%20Implementation**%20-%20Full%20working%20code%0A%20%20%20%204.%20**DTensor%20Re-sharding**%20-%20Computing%20transfer%20plans%2C%20the%20full%20benchmark%0A%0A%20%20%20%20This%20is%20the%20%22how%20it%20works%20under%20the%20hood%22%20companion%20to%20the%20main%20notebook.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%201.%20ibverbs%20Internals%0A%0A%20%20%20%20RDMA%20(Remote%20Direct%20Memory%20Access)%20lets%20one%20machine%20read%2Fwrite%20another%20machine's%20memory%0A%20%20%20%20directly%2C%20bypassing%20the%20kernel%20and%20CPU%20on%20both%20sides.%0A%0A%20%20%20%20%23%23%23%20The%20ibverbs%20Stack%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20Application%20(PyTorch%2C%20Monarch%2C%20etc.)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%0A%20%20%20%20%E2%94%82%20%20libibverbs%20%20(userspace%20RDMA%20API)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%0A%20%20%20%20%E2%94%82%20%20Provider%20driver%20(mlx5%2C%20efa%2C%20rxe%2C%20etc.)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%0A%20%20%20%20%E2%94%82%20%20Hardware%20(InfiniBand%20NIC%2C%20RoCE%20NIC%2C%20etc.)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20We%20focus%20on%20**InfiniBand**%20and%20**RoCE**%20(RDMA%20over%20Converged%20Ethernet).%0A%0A%20%20%20%20%23%23%23%20Key%20RDMA%20Operations%0A%0A%20%20%20%20%7C%20Operation%20%7C%20Description%20%7C%0A%20%20%20%20%7C-----------%7C-------------%7C%0A%20%20%20%20%7C%20%60RDMA_WRITE%60%20%7C%20Write%20to%20remote%20memory%20(one-sided)%20%7C%0A%20%20%20%20%7C%20%60RDMA_READ%60%20%7C%20Read%20from%20remote%20memory%20(one-sided)%20%7C%0A%20%20%20%20%7C%20%60SEND%2FRECV%60%20%7C%20Two-sided%20messaging%20(like%20TCP)%20%7C%0A%0A%20%20%20%20The%20magic%20is%20in%20%60RDMA_WRITE%60%20and%20%60RDMA_READ%60%20-%20they're%20**one-sided**%3A%0A%20%20%20%20-%20Remote%20CPU%20is%20not%20involved%0A%20%20%20%20-%20Remote%20application%20doesn't%20need%20to%20call%20anything%0A%20%20%20%20-%20NIC%20handles%20everything%20in%20hardware%0A%0A%20%20%20%20%23%23%23%20Memory%20Registration%0A%0A%20%20%20%20Before%20RDMA%2C%20memory%20must%20be%20**registered**%20with%20the%20NIC%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20Conceptually%20(actual%20ibverbs%20API%20is%20in%20C)%0A%20%20%20%20mr%20%3D%20rdma_register_memory(buffer%2C%20size)%0A%20%20%20%20%23%20Returns%3A%0A%20%20%20%20%23%20%20%20-%20lkey%3A%20local%20access%20key%20(for%20local%20operations)%0A%20%20%20%20%23%20%20%20-%20rkey%3A%20remote%20access%20key%20(share%20with%20remote%20peer)%0A%20%20%20%20%23%20%20%20-%20addr%3A%20physical%2Fvirtual%20address%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20%60(addr%2C%20rkey)%60%20pair%20is%20a%20**remote-accessible%20pointer**.%20Share%20it%20with%20a%20peer%2C%0A%20%20%20%20and%20they%20can%20read%2Fwrite%20your%20memory%20directly.%0A%0A%20%20%20%20%23%23%23%20Queue%20Pair%20Setup%0A%0A%20%20%20%20Before%20any%20RDMA%20operations%2C%20you%20need%20to%20establish%20a%20**Queue%20Pair%20(QP)**%20between%0A%20%20%20%20sender%20and%20receiver.%20This%20is%20a%20one-time%20connection%20setup%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20Sender%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20Receiver%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Create%20QP%20%20%E2%94%82%20%E2%94%80%E2%94%80%E2%94%80%20exchange%20QP%20info%20%E2%94%80%E2%94%80%E2%94%80%E2%96%BA%20%E2%94%82%20%20Create%20QP%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20(qp_num%2C%20%20%20%E2%94%82%20%E2%97%84%E2%94%80%E2%94%80%20(qp_num%2C%20lid%2C%20gid)%20%E2%94%80%E2%94%80%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20lid%2C%20gid)%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Move%20QP%20to%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20Move%20QP%20to%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20RTR%20%E2%86%92%20RTS%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20RTR%20%E2%86%92%20RTS%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Now%20ready%20%20%E2%94%82%20%E2%95%90%E2%95%90%E2%95%90%20RDMA%20operations%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%96%BA%20%E2%94%82%20%20Now%20ready%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20for%20RDMA!%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20for%20RDMA!%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20is%20where%20**Monarch%20actors**%20shine.%20Because%20you%20can%20spawn%20arbitrary%20actors%2C%0A%20%20%20%20you%20can%20create%20**RDMA%20Manager%20actors**%20that%3A%0A%20%20%20%20-%20Initialize%20QPs%20on%20their%20respective%20hosts%0A%20%20%20%20-%20Exchange%20QP%20info%20via%20actor%20messages%0A%20%20%20%20-%20Manage%20the%20connection%20lifecycle%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20Monarch%20pattern%3A%20RDMA%20managers%20as%20actors%0A%20%20%20%20class%20RDMAManager(Actor)%3A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.qp%20%3D%20create_queue_pair()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.qp_info%20%3D%20get_qp_info(self.qp)%20%20%23%20(qp_num%2C%20lid%2C%20gid)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_qp_info(self)%20-%3E%20QpInfo%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20self.qp_info%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20connect(self%2C%20remote_qp_info%3A%20QpInfo)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Transition%20QP%3A%20INIT%20%E2%86%92%20RTR%20%E2%86%92%20RTS%0A%20%20%20%20%20%20%20%20%20%20%20%20connect_qp(self.qp%2C%20remote_qp_info)%0A%0A%20%20%20%20%23%20Setup%3A%20exchange%20QP%20info%20via%20actor%20messages%2C%20then%20RDMA%20is%20ready%0A%20%20%20%20trainer_info%20%3D%20trainer_rdma.get_qp_info.call_one().get()%0A%20%20%20%20generator_rdma.connect.call_one(trainer_info).get()%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20actor%20abstraction%20makes%20RDMA%20connection%20management%20natural%20and%20composable.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Monarch%20Using%20Monarch%3A%20RdmaController%0A%0A%20%20%20%20Here's%20the%20cool%20part%3A%20**Monarch%20uses%20itself**%20to%20manage%20RDMA%20infrastructure.%20Looking%20at%0A%20%20%20%20the%20actual%20Python%20code%20in%20%60monarch%2F_src%2Frdma%2Frdma.py%60%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20From%20Monarch's%20RDMA%20implementation%0A%20%20%20%20from%20monarch._src.actor.proc_mesh%20import%20get_or_spawn_controller%0A%0A%20%20%20%20class%20RdmaController(Actor)%3A%0A%20%20%20%20%20%20%20%20'''Singleton%20controller%20that%20coordinates%20RDMA%20initialization.'''%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Track%20which%20proc%20meshes%20have%20RDMA%20initialized%0A%20%20%20%20%20%20%20%20%20%20%20%20self._manager_futures%3A%20dict%5BProcMesh%2C%20Future%5BRdmaManager%5D%5D%20%3D%20%7B%7D%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20async%20def%20init_rdma_on_mesh(self%2C%20proc_mesh%3A%20ProcMesh)%20-%3E%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20'''Lazily%20initialize%20RDMA%20on%20a%20proc%20mesh.'''%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20proc_mesh%20not%20in%20self._manager_futures%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self._manager_futures%5Bproc_mesh%5D%20%3D%20Future(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20coro%3DRdmaManager.create(proc_mesh)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20await%20self._manager_futures%5Bproc_mesh%5D%0A%0A%20%20%20%20%23%20Cached%20initialization%20-%20only%20runs%20once%20per%20process%0A%20%20%20%20%40functools.cache%0A%20%20%20%20def%20_ensure_init_rdma_manager()%3A%0A%20%20%20%20%20%20%20%20async%20def%20task()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20controller%20%3D%20await%20get_or_spawn_controller(%22rdma_controller%22%2C%20RdmaController)%0A%20%20%20%20%20%20%20%20%20%20%20%20await%20controller.init_rdma_on_mesh.call_one(current_proc_mesh())%0A%20%20%20%20%20%20%20%20return%20spawn_task(task())%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20is%20**Monarch%20building%20Monarch**%20-%20the%20RDMA%20subsystem%20uses%20the%20same%20patterns%3A%0A%0A%20%20%20%20-%20%60get_or_spawn_controller(%22rdma_controller%22%2C%20RdmaController)%60%20ensures%20one%20global%20controller%0A%20%20%20%20-%20The%20controller%20lazily%20initializes%20RDMA%20managers%20per%20proc%20mesh%0A%20%20%20%20-%20%60%40functools.cache%60%20ensures%20we%20only%20bootstrap%20once%20per%20process%0A%20%20%20%20-%20Under%20the%20hood%2C%20the%20actual%20RDMA%20operations%20are%20in%20Rust%20(%60RdmaManagerActor%60)%0A%0A%20%20%20%20It's%20actors%20all%20the%20way%20down.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%202.%20Memory%20Registration%20Costs%0A%0A%20%20%20%20RDMA%20memory%20registration%20is%20**expensive**%3A%0A%20%20%20%20-%20Pins%20physical%20pages%20(prevents%20swapping)%0A%20%20%20%20-%20Creates%20IOMMU%2FDMA%20mappings%20in%20the%20NIC%0A%20%20%20%20-%20Can%20take%20milliseconds%20for%20large%20buffers%0A%0A%20%20%20%20But%20here's%20the%20good%20news%3A%20**Monarch%20caches%20all%20memory%20region%20registrations.**%20Once%20a%20buffer%0A%20%20%20%20is%20registered%2C%20subsequent%20uses%20hit%20the%20cache%2C%20making%20it%20essentially%20free%20in%20steady%20state.%0A%0A%20%20%20%20Let's%20benchmark%203%20approaches%20to%20see%20this%20in%20action.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Approach%201%3A%20Naive%0A%0A%20%20%20%20Create%20new%20RDMABuffer%20on%20each%20transfer%20-%20registration%20happens%20on%20first%20use%3A%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Actor%2C%20RDMABuffer%2C%20current_rank%2C%20endpoint%2C%20time%2C%20torch)%3A%0A%20%20%20%20class%20NaiveSender(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Creates%20new%20RDMABuffer%20handles%20every%20transfer.%20Expensive!%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20layer_sizes%3A%20list)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layer_sizes%20%3D%20layer_sizes%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layers%20%3D%20%5Btorch.zeros(size%2C%20dtype%3Dtorch.float32)%20for%20size%20in%20layer_sizes%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%2C%20layer%20in%20enumerate(self.layers)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer.fill_(float(i%20%2B%201))%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_fresh_handles(self)%20-%3E%20list%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20handles%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20size%2C%20layer%20in%20zip(self.layer_sizes%2C%20self.layers)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20byte_view%20%3D%20layer.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handles.append((size%2C%20RDMABuffer(byte_view)))%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20handles%0A%0A%0A%20%20%20%20class%20NaiveReceiver(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Receives%20from%20naive%20sender%20-%20pays%20MR%20cost%20every%20step.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20layer_sizes%3A%20list)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layer_sizes%20%3D%20layer_sizes%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layers%20%3D%20%5Btorch.zeros(size%2C%20dtype%3Dtorch.float32)%20for%20size%20in%20layer_sizes%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.rank%20%3D%20current_rank().rank%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20receive_step(self%2C%20sender%3A%20NaiveSender)%20-%3E%20dict%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20handles%20%3D%20sender.get_fresh_handles.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%2C%20(size%2C%20handle)%20in%20enumerate(handles)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20byte_view%20%3D%20self.layers%5Bi%5D.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handle.read_into(byte_view).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20elapsed_ms%20%3D%20(time.perf_counter()%20-%20start)%20*%201000%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%22elapsed_ms%22%3A%20elapsed_ms%7D%0A%0A%20%20%20%20print(%22NaiveSender%3A%20Re-registers%20all%20parameters%20on%20every%20call%22)%0A%20%20%20%20return%20NaiveReceiver%2C%20NaiveSender%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Approach%202%3A%20Contiguous%20Buffer%0A%0A%20%20%20%20Allocate%20one%20buffer%2C%20register%20at%20init%20time%3A%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Actor%2C%20RDMABuffer%2C%20current_rank%2C%20endpoint%2C%20time%2C%20torch)%3A%0A%20%20%20%20class%20ContiguousSender(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22One%20buffer%2C%20one%20MR%2C%20registered%20at%20startup.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20layer_sizes%3A%20list)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layer_sizes%20%3D%20layer_sizes%0A%20%20%20%20%20%20%20%20%20%20%20%20total_size%20%3D%20sum(layer_sizes)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20One%20contiguous%20buffer%0A%20%20%20%20%20%20%20%20%20%20%20%20self.buffer%20%3D%20torch.zeros(total_size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20offset%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%2C%20size%20in%20enumerate(layer_sizes)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.buffer%5Boffset%20%3A%20offset%20%2B%20size%5D.fill_(float(i%20%2B%201))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20offset%20%2B%3D%20size%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Register%20ONCE%20at%20startup%0A%20%20%20%20%20%20%20%20%20%20%20%20byte_view%20%3D%20self.buffer.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.handle%20%3D%20RDMABuffer(byte_view)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_handle(self)%20-%3E%20tuple%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20(len(self.buffer)%2C%20self.handle)%20%20%23%20Same%20handle%20every%20time!%0A%0A%0A%20%20%20%20class%20ContiguousReceiver(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Receives%20from%20contiguous%20sender%20-%20fast%20after%20first%20step.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20total_size%3A%20int)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.buffer%20%3D%20torch.zeros(total_size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.rank%20%3D%20current_rank().rank%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20receive_step(self%2C%20sender%3A%20ContiguousSender)%20-%3E%20dict%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20size%2C%20handle%20%3D%20sender.get_handle.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20byte_view%20%3D%20self.buffer.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20handle.read_into(byte_view).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20elapsed_ms%20%3D%20(time.perf_counter()%20-%20start)%20*%201000%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%22elapsed_ms%22%3A%20elapsed_ms%7D%0A%0A%20%20%20%20print(%22ContiguousSender%3A%20Registers%20once%2C%20reuses%20same%20handle%22)%0A%20%20%20%20return%20ContiguousReceiver%2C%20ContiguousSender%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Approach%203%3A%20Scattered%20%2B%20RDMAAction%0A%0A%20%20%20%20Register%20each%20buffer%20at%20init%2C%20build%20transfer%20plan%20once%20via%20handshake%3A%0A%0A%20%20%20%20**What%20is%20RDMAAction%3F**%0A%0A%20%20%20%20Think%20of%20%60RDMAAction%60%20as%20a%20**transfer%20plan**.%20You%20describe%20all%20the%20reads%2Fwrites%20you%20want%0A%20%20%20%20to%20do%2C%20then%20%60submit()%60%20executes%20the%20whole%20plan%20at%20once%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20Build%20the%20plan%20once%0A%20%20%20%20action%20%3D%20RDMAAction()%0A%20%20%20%20action.read_into(handle1%2C%20local_buffer1)%0A%20%20%20%20action.read_into(handle2%2C%20local_buffer2)%0A%20%20%20%20action.read_into(handle3%2C%20local_buffer3)%0A%0A%20%20%20%20%23%20Execute%20whenever%20you%20want%20-%20just%20one%20call%0A%20%20%20%20action.submit().get()%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20is%20useful%20when%20you%20have%20many%20scattered%20buffers%20(like%20model%20parameters)%20and%20want%0A%20%20%20%20to%20batch%20them%20into%20a%20single%20logical%20operation.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Actor%2C%20RDMAAction%2C%20RDMABuffer%2C%20current_rank%2C%20endpoint%2C%20time%2C%20torch)%3A%0A%20%20%20%20class%20ScatteredSender(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Multiple%20buffers%2C%20each%20registered%20once%20at%20startup.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20layer_sizes%3A%20list)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layer_sizes%20%3D%20layer_sizes%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layers%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.handles%20%3D%20%5B%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%2C%20size%20in%20enumerate(layer_sizes)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer%20%3D%20torch.zeros(size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer.fill_(float(i%20%2B%201))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.layers.append(layer)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Register%20ONCE%20at%20startup%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20byte_view%20%3D%20layer.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.handles.append(RDMABuffer(byte_view))%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_handles(self)%20-%3E%20list%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%5B(size%2C%20handle)%20for%20size%2C%20handle%20in%20zip(self.layer_sizes%2C%20self.handles)%5D%0A%0A%20%20%20%20class%20ScatteredReceiver(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Receives%20from%20scattered%20sender%20with%20RDMAAction%20batching.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20layer_sizes%3A%20list)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layer_sizes%20%3D%20layer_sizes%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layers%20%3D%20%5Btorch.zeros(size%2C%20dtype%3Dtorch.float32)%20for%20size%20in%20layer_sizes%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.rank%20%3D%20current_rank().rank%0A%20%20%20%20%20%20%20%20%20%20%20%20self.action%20%3D%20None%20%20%23%20Built%20on%20handshake%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20handshake(self%2C%20sender%3A%20ScatteredSender)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Call%20once%20to%20build%20the%20RDMAAction%20transfer%20plan.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20handles%20%3D%20sender.get_handles.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.action%20%3D%20RDMAAction()%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%2C%20(size%2C%20handle)%20in%20enumerate(handles)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20byte_view%20%3D%20self.layers%5Bi%5D.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.action.read_into(handle%2C%20byte_view)%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%22Transfer%20plan%20ready%22%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20receive_step(self)%20-%3E%20dict%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Execute%20the%20cached%20transfer%20plan.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.action.submit().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20elapsed_ms%20%3D%20(time.perf_counter()%20-%20start)%20*%201000%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%22elapsed_ms%22%3A%20elapsed_ms%7D%0A%0A%20%20%20%20print(%22ScatteredSender%3A%20Registers%20each%20layer%20once%22)%0A%20%20%20%20print(%22ScatteredReceiver%3A%20handshake()%20builds%20plan%2C%20receive_step()%20executes%20it%22)%0A%20%20%20%20return%20ScatteredReceiver%2C%20ScatteredSender%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Running%20the%20Benchmark%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20ContiguousReceiver%2C%0A%20%20%20%20ContiguousSender%2C%0A%20%20%20%20NaiveReceiver%2C%0A%20%20%20%20NaiveSender%2C%0A%20%20%20%20ScatteredReceiver%2C%0A%20%20%20%20ScatteredSender%2C%0A%20%20%20%20this_host%2C%0A)%3A%0A%20%20%20%20def%20run_benchmark()%3A%0A%20%20%20%20%20%20%20%20%22%22%22Compare%20the%20three%20approaches%20over%20multiple%20steps.%22%22%22%0A%20%20%20%20%20%20%20%20layer_sizes%20%3D%20%5B1000%2C%205000%2C%202000%5D%20%20%23%208000%20floats%20total%0A%20%20%20%20%20%20%20%20total_size%20%3D%20sum(layer_sizes)%0A%20%20%20%20%20%20%20%20num_steps%20%3D%205%0A%0A%20%20%20%20%20%20%20%20host%20%3D%20this_host()%0A%20%20%20%20%20%20%20%20sender_procs%20%3D%20host.spawn_procs(per_host%3D%7B%22procs%22%3A%201%7D)%0A%20%20%20%20%20%20%20%20receiver_procs%20%3D%20host.spawn_procs(per_host%3D%7B%22procs%22%3A%201%7D)%0A%0A%20%20%20%20%20%20%20%20print(%22%3D%3D%3D%20RDMA%20Registration%20Benchmark%20%3D%3D%3D%22)%0A%20%20%20%20%20%20%20%20print(f%22Transferring%20%7Btotal_size%7D%20floats%20(%7Btotal_size%20*%204%20%2F%201024%3A.1f%7D%20KB)%20x%20%7Bnum_steps%7D%20steps%5Cn%22)%0A%0A%20%20%20%20%20%20%20%20results%20%3D%20%7B%7D%0A%0A%20%20%20%20%20%20%20%20%23%20Naive%20approach%0A%20%20%20%20%20%20%20%20naive_sender%20%3D%20sender_procs.spawn(%22naive_s%22%2C%20NaiveSender%2C%20layer_sizes)%0A%20%20%20%20%20%20%20%20naive_receiver%20%3D%20receiver_procs.spawn(%22naive_r%22%2C%20NaiveReceiver%2C%20layer_sizes)%0A%20%20%20%20%20%20%20%20times%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20step%20in%20range(num_steps)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20r%20%3D%20naive_receiver.receive_step.call_one(naive_sender).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20times.append(r%5B%22elapsed_ms%22%5D)%0A%20%20%20%20%20%20%20%20results%5B%22Naive%22%5D%20%3D%20times%0A%20%20%20%20%20%20%20%20print(f%22Naive%20(re-register%20each%20step)%3A%22)%0A%20%20%20%20%20%20%20%20for%20i%2C%20t%20in%20enumerate(times)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20Step%20%7Bi%2B1%7D%3A%20%7Bt%3A.2f%7Dms%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Average%3A%20%7Bsum(times)%2Flen(times)%3A.2f%7Dms%5Cn%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Contiguous%20approach%0A%20%20%20%20%20%20%20%20cont_sender%20%3D%20sender_procs.spawn(%22cont_s%22%2C%20ContiguousSender%2C%20layer_sizes)%0A%20%20%20%20%20%20%20%20cont_receiver%20%3D%20receiver_procs.spawn(%22cont_r%22%2C%20ContiguousReceiver%2C%20total_size)%0A%20%20%20%20%20%20%20%20times%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20step%20in%20range(num_steps)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20r%20%3D%20cont_receiver.receive_step.call_one(cont_sender).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20times.append(r%5B%22elapsed_ms%22%5D)%0A%20%20%20%20%20%20%20%20results%5B%22Contiguous%22%5D%20%3D%20times%0A%20%20%20%20%20%20%20%20print(f%22Contiguous%20(register%20once)%3A%22)%0A%20%20%20%20%20%20%20%20for%20i%2C%20t%20in%20enumerate(times)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20Step%20%7Bi%2B1%7D%3A%20%7Bt%3A.2f%7Dms%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Average%3A%20%7Bsum(times)%2Flen(times)%3A.2f%7Dms%5Cn%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Scattered%20%2B%20RDMAAction%20approach%0A%20%20%20%20%20%20%20%20scat_sender%20%3D%20sender_procs.spawn(%22scat_s%22%2C%20ScatteredSender%2C%20layer_sizes)%0A%20%20%20%20%20%20%20%20scat_receiver%20%3D%20receiver_procs.spawn(%22scat_r%22%2C%20ScatteredReceiver%2C%20layer_sizes)%0A%20%20%20%20%20%20%20%20scat_receiver.handshake.call_one(scat_sender).get()%20%20%23%20Build%20transfer%20plan%20once%0A%20%20%20%20%20%20%20%20times%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20step%20in%20range(num_steps)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20r%20%3D%20scat_receiver.receive_step.call_one().get()%20%20%23%20Just%20execute%20cached%20plan%0A%20%20%20%20%20%20%20%20%20%20%20%20times.append(r%5B%22elapsed_ms%22%5D)%0A%20%20%20%20%20%20%20%20results%5B%22Scattered%22%5D%20%3D%20times%0A%20%20%20%20%20%20%20%20print(f%22Scattered%20%2B%20RDMAAction%20(register%20once%2C%20batch)%3A%22)%0A%20%20%20%20%20%20%20%20for%20i%2C%20t%20in%20enumerate(times)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20Step%20%7Bi%2B1%7D%3A%20%7Bt%3A.2f%7Dms%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Average%3A%20%7Bsum(times)%2Flen(times)%3A.2f%7Dms%5Cn%22)%0A%0A%20%20%20%20%20%20%20%20print(%22%3D%3D%3D%20What's%20Happening%20%3D%3D%3D%22)%0A%20%20%20%20%20%20%20%20print(%22Naive%20step%201%3A%20Cold%20MR%20registration%20(~2000ms)%22)%0A%20%20%20%20%20%20%20%20print(%22Naive%20steps%202%2B%3A%20Cache%20hit%2C%20MR%20already%20registered%20(~10ms)%22)%0A%20%20%20%20%20%20%20%20print(%22Contiguous%2FScattered%3A%20Registration%20happened%20at%20spawn%20time%2C%20not%20during%20benchmark%22)%0A%0A%20%20%20%20%20%20%20%20return%20results%0A%0A%20%20%20%20benchmark_results%20%3D%20run_benchmark()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20**What%20the%20benchmark%20shows%3A**%0A%0A%20%20%20%20-%20**Naive**%3A%20First%20call%20is%20~2000ms%20(cold%20registration)%2C%20subsequent%20calls%20~10ms%20(cache%20hit)%0A%20%20%20%20-%20**Contiguous%2FScattered**%3A%20All%20calls%20are%20fast%20(~4-9ms)%20because%20registration%20happened%0A%20%20%20%20%20%20at%20spawn%20time%2C%20before%20the%20timing%20loop%20started%0A%0A%20%20%20%20*Note%3A%20RDMAAction%20(~9ms)%20is%20slower%20than%20Contiguous%20(~4ms)%20due%20to%20Python%20overhead.%0A%20%20%20%20Moving%20the%20batching%20logic%20to%20Rust%20is%20a%20planned%20optimization.*%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%203.%20Circular%20Weight%20Buffer%20Implementation%0A%0A%20%20%20%20Here's%20a%20full%20working%20implementation%20of%20a%20circular%20buffer%20for%20versioned%20weight%20storage.%0A%20%20%20%20In%20production%2C%20this%20would%20be%20used%20inside%20a%20Monarch%20actor%20and%20slots%20would%20be%20registered%0A%20%20%20%20with%20RDMABuffer%20at%20init%20time.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(torch)%3A%0A%20%20%20%20from%20threading%20import%20Lock%20as%20_Lock%0A%20%20%20%20from%20typing%20import%20Tuple%20as%20_Tuple%2C%20Optional%20as%20_Opt%0A%0A%20%20%20%20class%20CircularWeightBuffer%3A%0A%20%20%20%20%20%20%20%20%22%22%22Circular%20buffer%20for%20versioned%20weight%20storage.%0A%0A%20%20%20%20%20%20%20%20In%20production%2C%20this%20would%20be%20used%20inside%20a%20Monarch%20actor%20and%20slots%0A%20%20%20%20%20%20%20%20would%20be%20registered%20with%20RDMABuffer%20at%20init%20time.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20template_tensor%3A%20torch.Tensor%2C%20n_slots%3A%20int%20%3D%203)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.n_slots%20%3D%20n_slots%0A%20%20%20%20%20%20%20%20%20%20%20%20self.slots%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20torch.empty_like(template_tensor).pin_memory()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20template_tensor.device.type%20%3D%3D%20%22cpu%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%20torch.empty_like(template_tensor%2C%20device%3D%22cpu%22).pin_memory()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20_%20in%20range(n_slots)%0A%20%20%20%20%20%20%20%20%20%20%20%20%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.latest_version%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20self._lock%20%3D%20_Lock()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20In%20production%20(inside%20a%20Monarch%20actor)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20self.rdma_handles%20%3D%20%5BRDMABuffer(slot.view(torch.uint8).flatten())%20for%20slot%20in%20self.slots%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20This%20pre-registers%20all%20slots%20with%20RDMA%20at%20init%20time%20(amortizes%20MR%20cost)%0A%0A%20%20%20%20%20%20%20%20def%20publish(self%2C%20weights%3A%20torch.Tensor)%20-%3E%20int%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Trainer%20publishes%20new%20weights.%20Returns%20version%20number.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20with%20self._lock%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slot_idx%20%3D%20self.latest_version%20%25%20self.n_slots%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.slots%5Bslot_idx%5D.copy_(weights)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.latest_version%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.latest_version%20-%201%0A%0A%20%20%20%20%20%20%20%20def%20get_latest(self)%20-%3E%20_Tuple%5Btorch.Tensor%2C%20int%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Generator%20gets%20latest%20weights.%20Non-blocking.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20with%20self._lock%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20self.latest_version%20%3D%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20raise%20RuntimeError(%22No%20weights%20published%20yet%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slot_idx%20%3D%20(self.latest_version%20-%201)%20%25%20self.n_slots%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20version%20%3D%20self.latest_version%20-%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.slots%5Bslot_idx%5D.clone()%2C%20version%0A%0A%20%20%20%20%20%20%20%20def%20get_version(self%2C%20version%3A%20int)%20-%3E%20_Opt%5Btorch.Tensor%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Get%20specific%20version%20if%20still%20available.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20with%20self._lock%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20oldest_available%20%3D%20max(0%2C%20self.latest_version%20-%20self.n_slots)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20version%20%3C%20oldest_available%20or%20version%20%3E%3D%20self.latest_version%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20None%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slot_idx%20%3D%20version%20%25%20self.n_slots%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.slots%5Bslot_idx%5D.clone()%0A%0A%20%20%20%20%23%20Demo%0A%20%20%20%20_template%20%3D%20torch.randn(100%2C%20100)%0A%20%20%20%20weight_buffer%20%3D%20CircularWeightBuffer(_template%2C%20n_slots%3D3)%0A%0A%20%20%20%20%23%20Trainer%20publishes%20versions%0A%20%20%20%20for%20_v%20in%20range(5)%3A%0A%20%20%20%20%20%20%20%20_new_weights%20%3D%20torch.randn(100%2C%20100)%20*%20(_v%20%2B%201)%0A%20%20%20%20%20%20%20%20published_v%20%3D%20weight_buffer.publish(_new_weights)%0A%20%20%20%20%20%20%20%20print(f%22Published%20version%20%7Bpublished_v%7D%22)%0A%0A%20%20%20%20%23%20Generator%20grabs%20latest%0A%20%20%20%20latest_weights%2C%20latest_version%20%3D%20weight_buffer.get_latest()%0A%20%20%20%20print(f%22%5CnGenerator%20got%20version%20%7Blatest_version%7D%2C%20weights%20mean%3A%20%7Blatest_weights.mean()%3A.2f%7D%22)%0A%0A%20%20%20%20%23%20Try%20to%20get%20old%20version%20(might%20be%20evicted)%0A%20%20%20%20old_weights%20%3D%20weight_buffer.get_version(1)%0A%20%20%20%20print(f%22Version%201%20available%3A%20%7Bold_weights%20is%20not%20None%7D%22)%0A%0A%20%20%20%20print(%22%5CnIn%20production%3A%20RDMABuffer%20handles%20would%20be%20pre-registered%20at%20init%20time%22)%0A%20%20%20%20print(%22Generators%20would%20call%20get_latest_handle()%20to%20get%20RDMA%20handle%20%2B%20version%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%204.%20DTensor%20Re-sharding%20Implementation%0A%0A%20%20%20%20When%20trainer%20and%20generator%20have%20different%20tensor%20layouts%20(sharding)%2C%20we%20need%20to%20compute%0A%20%20%20%20which%20chunks%20of%20data%20need%20to%20move%20from%20which%20source%20to%20which%20destination.%0A%0A%20%20%20%20%23%23%23%20Computing%20Shard%20Metadata%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20from%20dataclasses%20import%20dataclass%0A%20%20%20%20from%20typing%20import%20List%2C%20Tuple%0A%0A%20%20%20%20%40dataclass%0A%20%20%20%20class%20ShardMetadata%3A%0A%20%20%20%20%20%20%20%20%22%22%22Metadata%20describing%20a%20tensor%20shard.%22%22%22%0A%20%20%20%20%20%20%20%20rank%3A%20int%0A%20%20%20%20%20%20%20%20global_shape%3A%20Tuple%5Bint%2C%20...%5D%0A%20%20%20%20%20%20%20%20offset%3A%20Tuple%5Bint%2C%20...%5D%20%20%23%20Start%20position%20in%20global%20tensor%0A%20%20%20%20%20%20%20%20local_shape%3A%20Tuple%5Bint%2C%20...%5D%20%20%23%20Shape%20of%20this%20shard%0A%0A%20%20%20%20def%20compute_shard_metadata(%0A%20%20%20%20%20%20%20%20global_shape%3A%20Tuple%5Bint%2C%20int%5D%2C%0A%20%20%20%20%20%20%20%20num_ranks%3A%20int%2C%0A%20%20%20%20%20%20%20%20shard_dim%3A%20int%2C%0A%20%20%20%20)%20-%3E%20List%5BShardMetadata%5D%3A%0A%20%20%20%20%20%20%20%20%22%22%22Compute%20shard%20metadata%20for%20a%20given%20sharding.%22%22%22%0A%20%20%20%20%20%20%20%20shards%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20dim_size%20%3D%20global_shape%5Bshard_dim%5D%0A%20%20%20%20%20%20%20%20shard_size%20%3D%20dim_size%20%2F%2F%20num_ranks%0A%0A%20%20%20%20%20%20%20%20for%20rank%20in%20range(num_ranks)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20offset%20%3D%20%5B0%2C%200%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20local_shape%20%3D%20list(global_shape)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20offset%5Bshard_dim%5D%20%3D%20rank%20*%20shard_size%0A%20%20%20%20%20%20%20%20%20%20%20%20local_shape%5Bshard_dim%5D%20%3D%20shard_size%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20shards.append(ShardMetadata(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rank%3Drank%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20global_shape%3Dglobal_shape%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20offset%3Dtuple(offset)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_shape%3Dtuple(local_shape)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20))%0A%0A%20%20%20%20%20%20%20%20return%20shards%0A%0A%20%20%20%20%23%20Demo%3A%20Trainer%20has%20row-sharding%2C%20Generator%20has%20column-sharding%0A%20%20%20%20_global_shape%20%3D%20(1024%2C%201024)%0A%0A%20%20%20%20trainer_shards%20%3D%20compute_shard_metadata(_global_shape%2C%20num_ranks%3D4%2C%20shard_dim%3D0)%0A%20%20%20%20generator_shards%20%3D%20compute_shard_metadata(_global_shape%2C%20num_ranks%3D2%2C%20shard_dim%3D1)%0A%0A%20%20%20%20print(%22Trainer%20shards%20(row-wise%2C%204%20GPUs)%3A%22)%0A%20%20%20%20for%20s%20in%20trainer_shards%3A%0A%20%20%20%20%20%20%20%20print(f%22%20%20Rank%20%7Bs.rank%7D%3A%20offset%3D%7Bs.offset%7D%2C%20shape%3D%7Bs.local_shape%7D%22)%0A%0A%20%20%20%20print(%22%5CnGenerator%20shards%20(column-wise%2C%202%20GPUs)%3A%22)%0A%20%20%20%20for%20s%20in%20generator_shards%3A%0A%20%20%20%20%20%20%20%20print(f%22%20%20Rank%20%7Bs.rank%7D%3A%20offset%3D%7Bs.offset%7D%2C%20shape%3D%7Bs.local_shape%7D%22)%0A%20%20%20%20return%20(%0A%20%20%20%20%20%20%20%20List%2C%0A%20%20%20%20%20%20%20%20ShardMetadata%2C%0A%20%20%20%20%20%20%20%20Tuple%2C%0A%20%20%20%20%20%20%20%20compute_shard_metadata%2C%0A%20%20%20%20%20%20%20%20dataclass%2C%0A%20%20%20%20%20%20%20%20generator_shards%2C%0A%20%20%20%20%20%20%20%20trainer_shards%2C%0A%20%20%20%20)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Computing%20Transfer%20Plans%0A%0A%20%20%20%20Given%20source%20and%20destination%20sharding%2C%20compute%20the%20minimal%20set%20of%20transfers%20needed%3A%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(List%2C%20ShardMetadata%2C%20Tuple%2C%20dataclass%2C%20generator_shards%2C%20trainer_shards)%3A%0A%20%20%20%20%40dataclass%0A%20%20%20%20class%20TransferChunk%3A%0A%20%20%20%20%20%20%20%20%22%22%22A%20chunk%20to%20transfer%20from%20sender%20to%20receiver.%22%22%22%0A%20%20%20%20%20%20%20%20sender_rank%3A%20int%0A%20%20%20%20%20%20%20%20receiver_rank%3A%20int%0A%20%20%20%20%20%20%20%20sender_offset%3A%20Tuple%5Bint%2C%20int%5D%20%20%23%20Where%20to%20read%20from%20sender%0A%20%20%20%20%20%20%20%20receiver_offset%3A%20Tuple%5Bint%2C%20int%5D%20%20%23%20Where%20to%20write%20in%20receiver%0A%20%20%20%20%20%20%20%20shape%3A%20Tuple%5Bint%2C%20int%5D%20%20%23%20Shape%20of%20the%20chunk%0A%0A%20%20%20%20def%20compute_overlap(%0A%20%20%20%20%20%20%20%20sender%3A%20ShardMetadata%2C%0A%20%20%20%20%20%20%20%20receiver%3A%20ShardMetadata%2C%0A%20%20%20%20)%20-%3E%20TransferChunk%20%7C%20None%3A%0A%20%20%20%20%20%20%20%20%22%22%22Compute%20overlap%20between%20sender%20and%20receiver%20shards.%22%22%22%0A%20%20%20%20%20%20%20%20%23%20Find%20intersection%20in%20global%20coordinates%0A%20%20%20%20%20%20%20%20s_start%20%3D%20sender.offset%0A%20%20%20%20%20%20%20%20s_end%20%3D%20(s_start%5B0%5D%20%2B%20sender.local_shape%5B0%5D%2C%20s_start%5B1%5D%20%2B%20sender.local_shape%5B1%5D)%0A%0A%20%20%20%20%20%20%20%20r_start%20%3D%20receiver.offset%0A%20%20%20%20%20%20%20%20r_end%20%3D%20(r_start%5B0%5D%20%2B%20receiver.local_shape%5B0%5D%2C%20r_start%5B1%5D%20%2B%20receiver.local_shape%5B1%5D)%0A%0A%20%20%20%20%20%20%20%20%23%20Compute%20intersection%0A%20%20%20%20%20%20%20%20inter_start%20%3D%20(max(s_start%5B0%5D%2C%20r_start%5B0%5D)%2C%20max(s_start%5B1%5D%2C%20r_start%5B1%5D))%0A%20%20%20%20%20%20%20%20inter_end%20%3D%20(min(s_end%5B0%5D%2C%20r_end%5B0%5D)%2C%20min(s_end%5B1%5D%2C%20r_end%5B1%5D))%0A%0A%20%20%20%20%20%20%20%20%23%20Check%20if%20there's%20actual%20overlap%0A%20%20%20%20%20%20%20%20if%20inter_start%5B0%5D%20%3E%3D%20inter_end%5B0%5D%20or%20inter_start%5B1%5D%20%3E%3D%20inter_end%5B1%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20None%0A%0A%20%20%20%20%20%20%20%20shape%20%3D%20(inter_end%5B0%5D%20-%20inter_start%5B0%5D%2C%20inter_end%5B1%5D%20-%20inter_start%5B1%5D)%0A%0A%20%20%20%20%20%20%20%20%23%20Convert%20to%20local%20coordinates%0A%20%20%20%20%20%20%20%20sender_local%20%3D%20(inter_start%5B0%5D%20-%20s_start%5B0%5D%2C%20inter_start%5B1%5D%20-%20s_start%5B1%5D)%0A%20%20%20%20%20%20%20%20receiver_local%20%3D%20(inter_start%5B0%5D%20-%20r_start%5B0%5D%2C%20inter_start%5B1%5D%20-%20r_start%5B1%5D)%0A%0A%20%20%20%20%20%20%20%20return%20TransferChunk(%0A%20%20%20%20%20%20%20%20%20%20%20%20sender_rank%3Dsender.rank%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20receiver_rank%3Dreceiver.rank%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20sender_offset%3Dsender_local%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20receiver_offset%3Dreceiver_local%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20shape%3Dshape%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20def%20compute_transfer_plan(%0A%20%20%20%20%20%20%20%20sender_shards%3A%20List%5BShardMetadata%5D%2C%0A%20%20%20%20%20%20%20%20receiver_shards%3A%20List%5BShardMetadata%5D%2C%0A%20%20%20%20)%20-%3E%20List%5BTransferChunk%5D%3A%0A%20%20%20%20%20%20%20%20%22%22%22Compute%20all%20transfers%20needed%20for%20re-sharding.%22%22%22%0A%20%20%20%20%20%20%20%20transfers%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20sender%20in%20sender_shards%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20receiver%20in%20receiver_shards%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20chunk%20%3D%20compute_overlap(sender%2C%20receiver)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20chunk%20is%20not%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20transfers.append(chunk)%0A%20%20%20%20%20%20%20%20return%20transfers%0A%0A%20%20%20%20%23%20Compute%20transfer%20plan%0A%20%20%20%20transfer_plan%20%3D%20compute_transfer_plan(trainer_shards%2C%20generator_shards)%0A%0A%20%20%20%20print(f%22Transfer%20plan%3A%20%7Blen(transfer_plan)%7D%20chunks%20needed%5Cn%22)%0A%20%20%20%20for%20chunk%20in%20transfer_plan%3A%0A%20%20%20%20%20%20%20%20print(f%22Sender%20%7Bchunk.sender_rank%7D%20%E2%86%92%20Receiver%20%7Bchunk.receiver_rank%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Read%20from%20sender%20offset%20%7Bchunk.sender_offset%7D%2C%20shape%20%7Bchunk.shape%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Write%20to%20receiver%20offset%20%7Bchunk.receiver_offset%7D%22)%0A%20%20%20%20%20%20%20%20print()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Full%20DTensor%20Benchmark%0A%0A%20%20%20%20This%20benchmark%20uses%20actual%20DTensor%20with%20different%20placements%20to%20show%20the%20savings%0A%20%20%20%20from%20routed%20transfers%20vs%20gather-then-slice.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20Actor%2C%0A%20%20%20%20RDMAAction%2C%0A%20%20%20%20RDMABuffer%2C%0A%20%20%20%20compute_shard_metadata%2C%0A%20%20%20%20current_rank%2C%0A%20%20%20%20endpoint%2C%0A%20%20%20%20time%2C%0A%20%20%20%20torch%2C%0A)%3A%0A%20%20%20%20import%20os%0A%20%20%20%20from%20torch.distributed._tensor%20import%20DTensor%2C%20Shard%2C%20Replicate%2C%20init_device_mesh%0A%0A%20%20%20%20%23%20Configuration%0A%20%20%20%20NUM_TRAINER_RANKS%20%3D%204%0A%20%20%20%20NUM_GENERATOR_RANKS%20%3D%202%0A%0A%20%20%20%20%23%20Layer%20configs%3A%20(global_shape%2C%20trainer_placement%2C%20generator_placement)%0A%20%20%20%20LAYER_CONFIGS%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%7B%22shape%22%3A%20(1024%2C%201024)%2C%20%22trainer_place%22%3A%20Shard(0)%2C%20%22gen_place%22%3A%20Shard(0)%7D%2C%0A%20%20%20%20%20%20%20%20%7B%22shape%22%3A%20(512%2C%202048)%2C%20%22trainer_place%22%3A%20Shard(1)%2C%20%22gen_place%22%3A%20Shard(1)%7D%2C%0A%20%20%20%20%20%20%20%20%7B%22shape%22%3A%20(256%2C%20256)%2C%20%22trainer_place%22%3A%20Replicate()%2C%20%22gen_place%22%3A%20Replicate()%7D%2C%0A%20%20%20%20%5D%0A%0A%20%20%20%20def%20placement_to_shard_dim(placement)%20-%3E%20int%20%7C%20None%3A%0A%20%20%20%20%20%20%20%20%22%22%22Extract%20shard%20dimension%20from%20DTensor%20placement.%22%22%22%0A%20%20%20%20%20%20%20%20if%20isinstance(placement%2C%20Shard)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20placement.dim%0A%20%20%20%20%20%20%20%20return%20None%0A%0A%20%20%20%20def%20compute_layer_transfer_plan(layer_cfg%2C%20trainer_ranks%2C%20gen_ranks%2C%20gen_rank)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Use%20DTensor%20placement%20metadata%20to%20compute%20transfer%20plan%20for%20one%20layer.%22%22%22%0A%20%20%20%20%20%20%20%20trainer_dim%20%3D%20placement_to_shard_dim(layer_cfg%5B%22trainer_place%22%5D)%0A%20%20%20%20%20%20%20%20gen_dim%20%3D%20placement_to_shard_dim(layer_cfg%5B%22gen_place%22%5D)%0A%0A%20%20%20%20%20%20%20%20if%20trainer_dim%20is%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%5B(0%2C%20None)%5D%0A%0A%20%20%20%20%20%20%20%20if%20gen_dim%20is%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%5B(t%2C%20None)%20for%20t%20in%20range(trainer_ranks)%5D%0A%0A%20%20%20%20%20%20%20%20trainer_shards%20%3D%20compute_shard_metadata(layer_cfg%5B%22shape%22%5D%2C%20trainer_ranks%2C%20trainer_dim)%0A%20%20%20%20%20%20%20%20gen_shards%20%3D%20compute_shard_metadata(layer_cfg%5B%22shape%22%5D%2C%20gen_ranks%2C%20gen_dim)%0A%20%20%20%20%20%20%20%20my_shard%20%3D%20gen_shards%5Bgen_rank%5D%0A%0A%20%20%20%20%20%20%20%20overlapping%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20t_shard%20in%20trainer_shards%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20t_start%20%3D%20t_shard.offset%5Btrainer_dim%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20t_end%20%3D%20t_start%20%2B%20t_shard.local_shape%5Btrainer_dim%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20g_start%20%3D%20my_shard.offset%5Bgen_dim%5D%20if%20gen_dim%20%3D%3D%20trainer_dim%20else%200%0A%20%20%20%20%20%20%20%20%20%20%20%20g_end%20%3D%20(my_shard.offset%5Bgen_dim%5D%20%2B%20my_shard.local_shape%5Bgen_dim%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20gen_dim%20%3D%3D%20trainer_dim%20else%20layer_cfg%5B%22shape%22%5D%5Btrainer_dim%5D)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20t_end%20%3E%20g_start%20and%20t_start%20%3C%20g_end%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20overlapping.append((t_shard.rank%2C%20t_shard))%0A%0A%20%20%20%20%20%20%20%20return%20overlapping%0A%0A%20%20%20%20class%20DTensorTrainer(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Trainer%20with%20DTensor%20shards.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.rank%20%3D%20current_rank().rank%0A%20%20%20%20%20%20%20%20%20%20%20%20self.dtensors%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.handles%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.device_mesh%20%3D%20None%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20setup_distributed(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20world_size%20%3D%20int(os.environ.get(%22WORLD_SIZE%22%2C%20%221%22))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20not%20torch.distributed.is_initialized()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20torch.distributed.init_process_group(backend%3D%22gloo%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.device_mesh%20%3D%20init_device_mesh(%22cpu%22%2C%20(world_size%2C))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%2C%20cfg%20in%20enumerate(LAYER_CONFIGS)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20placement%20%3D%20cfg%5B%22trainer_place%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20shard_dim%20%3D%20placement_to_shard_dim(placement)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20shard_dim%20is%20not%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_shape%20%3D%20list(cfg%5B%22shape%22%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_shape%5Bshard_dim%5D%20%3D%20cfg%5B%22shape%22%5D%5Bshard_dim%5D%20%2F%2F%20world_size%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_shape%20%3D%20tuple(local_shape)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_shape%20%3D%20cfg%5B%22shape%22%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_tensor%20%3D%20torch.zeros(local_shape%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_tensor.fill_(float(i%20*%2010%20%2B%20self.rank))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20dt%20%3D%20DTensor.from_local(local_tensor%2C%20self.device_mesh%2C%20%5Bplacement%5D%2C%20run_check%3DFalse)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.dtensors.append(dt)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.handles.append(RDMABuffer(local_tensor.view(torch.uint8).flatten()))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20shapes%20%3D%20%5Btuple(dt.to_local().shape)%20for%20dt%20in%20self.dtensors%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20placements%20%3D%20%5Bstr(cfg%5B%22trainer_place%22%5D)%20for%20cfg%20in%20LAYER_CONFIGS%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22Trainer%20%7Bself.rank%7D%3A%20shapes%3D%7Bshapes%7D%2C%20placements%3D%7Bplacements%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20shapes%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_layer_handle(self%2C%20layer_idx%3A%20int)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20(tuple(self.dtensors%5Blayer_idx%5D.to_local().shape)%2C%20self.handles%5Blayer_idx%5D)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20destroy(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20torch.distributed.is_initialized()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20torch.distributed.destroy_process_group()%0A%0A%20%20%20%20class%20DTensorGenerator(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Generator%20that%20uses%20DTensor%20placement%20metadata%20for%20smart%20resharding.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.rank%20%3D%20current_rank().rank%0A%20%20%20%20%20%20%20%20%20%20%20%20self.action%20%3D%20None%0A%20%20%20%20%20%20%20%20%20%20%20%20self.recv_buffers%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.device_mesh%20%3D%20None%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20setup_distributed(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20world_size%20%3D%20int(os.environ.get(%22WORLD_SIZE%22%2C%20%221%22))%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20not%20torch.distributed.is_initialized()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20torch.distributed.init_process_group(backend%3D%22gloo%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.device_mesh%20%3D%20init_device_mesh(%22cpu%22%2C%20(world_size%2C))%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22Generator%20%7Bself.rank%7D%3A%20distributed%20initialized%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20world_size%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20handshake_routed(self%2C%20trainers)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Routed%20approach%3A%20use%20DTensor%20placements%20to%20compute%20minimal%20transfers.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20self.action%20%3D%20RDMAAction()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.recv_buffers%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20total_transfers%20%3D%200%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20layer_idx%2C%20cfg%20in%20enumerate(LAYER_CONFIGS)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20overlapping%20%3D%20compute_layer_transfer_plan(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cfg%2C%20NUM_TRAINER_RANKS%2C%20NUM_GENERATOR_RANKS%2C%20self.rank%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20t_rank%2C%20_%20in%20overlapping%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20shape%2C%20handle%20%3D%20trainers%5Bt_rank%5D.get_layer_handle.call_one(layer_idx).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20buf%20%3D%20torch.zeros(shape%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.recv_buffers.append(buf)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.action.read_into(handle%2C%20buf.view(torch.uint8).flatten())%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20total_transfers%20%2B%3D%201%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20f%22Routed%3A%20%7Btotal_transfers%7D%20transfers%20(placement-aware)%22%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20receive_routed(self)%20-%3E%20dict%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.action.submit().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20elapsed_ms%20%3D%20(time.perf_counter()%20-%20start)%20*%201000%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%22elapsed_ms%22%3A%20elapsed_ms%7D%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20destroy(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20torch.distributed.is_initialized()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20torch.distributed.destroy_process_group()%0A%0A%20%20%20%20print(%22DTensor%20actors%20defined%22)%0A%20%20%20%20return%20(%0A%20%20%20%20%20%20%20%20DTensorGenerator%2C%0A%20%20%20%20%20%20%20%20DTensorTrainer%2C%0A%20%20%20%20%20%20%20%20LAYER_CONFIGS%2C%0A%20%20%20%20%20%20%20%20NUM_GENERATOR_RANKS%2C%0A%20%20%20%20%20%20%20%20NUM_TRAINER_RANKS%2C%0A%20%20%20%20)%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20DTensorGenerator%2C%0A%20%20%20%20DTensorTrainer%2C%0A%20%20%20%20LAYER_CONFIGS%2C%0A%20%20%20%20NUM_GENERATOR_RANKS%2C%0A%20%20%20%20NUM_TRAINER_RANKS%2C%0A%20%20%20%20this_host%2C%0A%20%20%20%20time%2C%0A)%3A%0A%20%20%20%20from%20monarch.spmd%20import%20setup_torch_elastic_env%0A%0A%20%20%20%20_trainer_procs%20%3D%20this_host().spawn_procs(per_host%3D%7B%22procs%22%3A%20NUM_TRAINER_RANKS%7D)%0A%20%20%20%20setup_torch_elastic_env(_trainer_procs)%0A%20%20%20%20_trainers%20%3D%20_trainer_procs.spawn(%22trainers%22%2C%20DTensorTrainer)%0A%0A%20%20%20%20_gen_procs%20%3D%20this_host().spawn_procs(per_host%3D%7B%22procs%22%3A%20NUM_GENERATOR_RANKS%7D)%0A%20%20%20%20setup_torch_elastic_env(_gen_procs)%0A%20%20%20%20_generators%20%3D%20_gen_procs.spawn(%22generators%22%2C%20DTensorGenerator)%0A%0A%20%20%20%20print(%22%5Cn%3D%3D%3D%20DTensor%20Reshard%20Benchmark%20%3D%3D%3D%22)%0A%20%20%20%20print(f%22Trainer%20mesh%3A%20%7BNUM_TRAINER_RANKS%7D%20ranks%2C%20Generator%20mesh%3A%20%7BNUM_GENERATOR_RANKS%7D%20ranks%22)%0A%20%20%20%20print(%22Layer%20configs%3A%22)%0A%20%20%20%20for%20i%2C%20cfg%20in%20enumerate(LAYER_CONFIGS)%3A%0A%20%20%20%20%20%20%20%20print(f%22%20%20Layer%20%7Bi%7D%3A%20%7Bcfg%5B'shape'%5D%7D%2C%20trainer%3D%7Bcfg%5B'trainer_place'%5D%7D%2C%20gen%3D%7Bcfg%5B'gen_place'%5D%7D%22)%0A%0A%20%20%20%20print(%22%5CnSetting%20up%20distributed...%22)%0A%20%20%20%20_trainer_shapes%20%3D%20_trainers.setup_distributed.call().get()%0A%20%20%20%20_gen_world%20%3D%20_generators.setup_distributed.call().get()%0A%20%20%20%20print(f%22%20%20Trainer%20shapes%3A%20%7B%5Bs%20for%20_%2C%20s%20in%20_trainer_shapes%5D%7D%22)%0A%20%20%20%20print(f%22%20%20Generator%20world%20sizes%3A%20%7B%5Bw%20for%20_%2C%20w%20in%20_gen_world%5D%7D%22)%0A%0A%20%20%20%20_trainer_list%20%3D%20%5B_trainers.slice(procs%3Di)%20for%20i%20in%20range(NUM_TRAINER_RANKS)%5D%0A%0A%20%20%20%20print(%22%5CnBuilding%20transfer%20plans%20(using%20placement%20metadata)...%22)%0A%20%20%20%20_results%20%3D%20_generators.handshake_routed.call(_trainer_list).get()%0A%20%20%20%20for%20_i%2C%20_r%20in%20enumerate(_results)%3A%0A%20%20%20%20%20%20%20%20print(f%22%20%20Generator%20%7B_i%7D%3A%20%7B_r%7D%22)%0A%0A%20%20%20%20print(%22%5CnRunning%20transfers...%22)%0A%20%20%20%20_times%20%3D%20%5B%5D%0A%20%20%20%20for%20_step%20in%20range(3)%3A%0A%20%20%20%20%20%20%20%20_step_start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20_results%20%3D%20_generators.receive_routed.call().get()%0A%20%20%20%20%20%20%20%20_step_ms%20%3D%20(time.perf_counter()%20-%20_step_start)%20*%201000%0A%20%20%20%20%20%20%20%20_times.append(_step_ms)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Step%20%7B_step%20%2B%201%7D%3A%20%7B_step_ms%3A.1f%7Dms%22)%0A%0A%20%20%20%20_avg%20%3D%20sum(_times)%20%2F%20len(_times)%0A%20%20%20%20print(f%22%20%20Average%3A%20%7B_avg%3A.1f%7Dms%22)%0A%0A%20%20%20%20_trainers.destroy.call().get()%0A%20%20%20%20_generators.destroy.call().get()%0A%20%20%20%20print(%22%5CnDistributed%20cleanup%20complete%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Summary%0A%0A%20%20%20%20This%20deep%20dive%20covered%3A%0A%0A%20%20%20%201.%20**ibverbs%20internals**%20-%20QP%20setup%2C%20MR%20registration%2C%20how%20Monarch%20wraps%20it%20all%0A%20%20%20%202.%20**Memory%20registration%20costs**%20-%20Why%20naive%20approaches%20are%20slow%2C%20how%20caching%20helps%0A%20%20%20%203.%20**Circular%20weight%20buffers**%20-%20Full%20implementation%20with%20versioning%0A%20%20%20%204.%20**DTensor%20re-sharding**%20-%20Computing%20transfer%20plans%20from%20placement%20metadata%0A%0A%20%20%20%20These%20are%20the%20building%20blocks%20that%20make%20Monarch's%20weight%20sync%20fast%20and%20flexible.%0A%20%20%20%20The%20main%20notebook%20(06)%20covers%20when%20and%20why%20to%20use%20these%20patterns.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0Aif%20__name__%20%3D%3D%20%22__main__%22%3A%0A%20%20%20%20app.run()%0A
</marimo-code>

<marimo-code-hash hidden="">fbbd0df18e23050ab0aed5b991e38c15</marimo-code-hash>
</body>
</html>
